{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "introduction-to-hugging-face-transformers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "074ceb970ad64440b732c71c7499b899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45713ad625a34604b196484e115df443",
              "IPY_MODEL_aa885cb072984c7380376ffeeadc36c0",
              "IPY_MODEL_46a3e9cb76d1409fa1bf0d2b81bc1594"
            ],
            "layout": "IPY_MODEL_cf5a7342b60d4e078ce1786686d76565"
          }
        },
        "45713ad625a34604b196484e115df443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d94b7cc87b44476b4dac9113096b03c",
            "placeholder": "​",
            "style": "IPY_MODEL_ba7e1956531148bca3fa2a101c9a6729",
            "value": "100%"
          }
        },
        "aa885cb072984c7380376ffeeadc36c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d60592f49e84401bb9fb78f33f30702",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41c2001d640546679abad1e6dd4af760",
            "value": 3
          }
        },
        "46a3e9cb76d1409fa1bf0d2b81bc1594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bbce800fabc4988b393dd241aed679e",
            "placeholder": "​",
            "style": "IPY_MODEL_908c69f4a15941869582c9f4ad1334da",
            "value": " 3/3 [00:00&lt;00:00, 105.54it/s]"
          }
        },
        "cf5a7342b60d4e078ce1786686d76565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d94b7cc87b44476b4dac9113096b03c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba7e1956531148bca3fa2a101c9a6729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d60592f49e84401bb9fb78f33f30702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c2001d640546679abad1e6dd4af760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bbce800fabc4988b393dd241aed679e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "908c69f4a15941869582c9f4ad1334da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38eaafe06c2a4a57b1c77fcef71aa5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad964dfac1724ed298dcbcdbd8e893a7",
              "IPY_MODEL_b6ead70dd2014796a165df5ba1d19392",
              "IPY_MODEL_e3dcc6f77b6547e4a8d3a66a215191be"
            ],
            "layout": "IPY_MODEL_1fee7919d3c04991b50c9ed15660caac"
          }
        },
        "ad964dfac1724ed298dcbcdbd8e893a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af789af462d9488c8552e5689aeb8022",
            "placeholder": "​",
            "style": "IPY_MODEL_d37870a5198945fca2b94dbeb488ea5b",
            "value": "100%"
          }
        },
        "b6ead70dd2014796a165df5ba1d19392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b41115514934624bce5fa1eaf24db49",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0bc507fb2094f4698472197cb7d141a",
            "value": 50
          }
        },
        "e3dcc6f77b6547e4a8d3a66a215191be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f2a808abe904d3bb8b9f3cbfbee0d0e",
            "placeholder": "​",
            "style": "IPY_MODEL_c93adf60344b45e9ba5e1323fa059daf",
            "value": " 50/50 [00:34&lt;00:00,  1.05s/ba]"
          }
        },
        "1fee7919d3c04991b50c9ed15660caac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af789af462d9488c8552e5689aeb8022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d37870a5198945fca2b94dbeb488ea5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b41115514934624bce5fa1eaf24db49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0bc507fb2094f4698472197cb7d141a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f2a808abe904d3bb8b9f3cbfbee0d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93adf60344b45e9ba5e1323fa059daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fa1670400394d019b76a536401a7a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f21d7097ab6a45c1a30b6beeaa3c8e2b",
              "IPY_MODEL_8c5cc9de89a740bc9a1d3a40fe939424",
              "IPY_MODEL_e8fdef4d003d4278aa578e02cfac75e9"
            ],
            "layout": "IPY_MODEL_73fa95f2b134445cac806ddf7dde2c66"
          }
        },
        "f21d7097ab6a45c1a30b6beeaa3c8e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5945a3b9765245e990f0d0452e4f5079",
            "placeholder": "​",
            "style": "IPY_MODEL_9cc8e2400a374d1b90f82feef8135a5b",
            "value": "100%"
          }
        },
        "8c5cc9de89a740bc9a1d3a40fe939424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d5cb66521746b5a62b2d1159ca0933",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_170d94f26688439eaebafd7200dbc319",
            "value": 3
          }
        },
        "e8fdef4d003d4278aa578e02cfac75e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_307772fd1a1a4049b86704be6af91b5f",
            "placeholder": "​",
            "style": "IPY_MODEL_842913374af5461a9cebc50fea3dd7bd",
            "value": " 3/3 [00:00&lt;00:00, 44.32it/s]"
          }
        },
        "73fa95f2b134445cac806ddf7dde2c66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5945a3b9765245e990f0d0452e4f5079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cc8e2400a374d1b90f82feef8135a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d5cb66521746b5a62b2d1159ca0933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170d94f26688439eaebafd7200dbc319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "307772fd1a1a4049b86704be6af91b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "842913374af5461a9cebc50fea3dd7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabnancyuhp/DEEP-LEARNING/blob/main/NOTEBOOKS/introduction-to-hugging-face-transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref : https://huggingface.co/transformers/training.html<br>\n",
        "ref : https://huggingface.co/docs/datasets/loading_datasets.html<br>\n",
        "ref : https://blog.tensorflow.org/2019/11/hugging-face-state-of-art-natural.html<br>\n",
        "In this notebook, \n",
        "* we will see a text classification implementation on the IMDB dataset with the Transfer Learning technique. \n",
        "* we will show how to fine-tune a pretrained model from the Transformers library. \n",
        "* we will fine-tune BERT on the IMDB dataset\n",
        "\n",
        "BERT stands for Bidirectional Encoder Representations from Transformers. In TensorFlow, models can be directly trained using Keras and the fit method.<br><br>\n",
        "\n",
        "**Hugging Face** is an NLP-focused startup with a large open-source community, in particular around the **Transformers library.** 🤗/Transformers is a python-based library that exposes an API to use many well-known transformer architectures, such as BERT, RoBERTa, GPT-2 or DistilBERT, that obtain state-of-the-art results on a variety of NLP tasks like text classification, information extraction, question answering, and text generation. Those architectures come pre-trained with several sets of weights.<br><br>\n",
        "\n",
        "The **Transformers library** has seen super-fast growth in PyTorch and has recently been ported to TensorFlow 2.0, offering an API that now works with Keras’ fit API, TensorFlow Extended, and TPUs<br><br>\n",
        "\n",
        "**Hugging Face transformers** is a collection of state-of-the-art NLP (Natural Language Processing) models. They offer a wide variety of architectures to choose from (BERT, GPT-2, RoBERTa etc) as well as a hub of pre-trained models uploaded by users and organisations. <br><br>\n",
        "**Hugging Face Datasets** is a wrapper library that provides some tools to load and process data in many commonly used formats (CSV, JSON etc)."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-15T07:26:44.471907Z",
          "iopub.execute_input": "2021-09-15T07:26:44.472211Z",
          "iopub.status.idle": "2021-09-15T07:27:36.05847Z",
          "shell.execute_reply.started": "2021-09-15T07:26:44.472134Z",
          "shell.execute_reply": "2021-09-15T07:27:36.057214Z"
        },
        "id": "DQJU0IsabaVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face Datasets\n",
        "**Hugging Face Datasets** is a wrapper library that provides some tools to load and process data in many commonly used formats (CSV, JSON etc).<br><br>\n",
        "Before we can fine-tune a model, we need a dataset. In this tutorial, we will show you how to fine-tune BERT on the IMDB dataset: the task is to classify whether movie reviews are positive or negative. Bellow, we load the IMBD data structure from the hugging-face hub. Row_datasets is DatasetDict object."
      ],
      "metadata": {
        "id": "A_lUHWMFbaVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "S1yLLk9AbaVv",
        "outputId": "c96363df-f629-49e6-fd22-abcaee87ed91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "074ceb970ad64440b732c71c7499b899",
            "45713ad625a34604b196484e115df443",
            "aa885cb072984c7380376ffeeadc36c0",
            "46a3e9cb76d1409fa1bf0d2b81bc1594",
            "cf5a7342b60d4e078ce1786686d76565",
            "7d94b7cc87b44476b4dac9113096b03c",
            "ba7e1956531148bca3fa2a101c9a6729",
            "9d60592f49e84401bb9fb78f33f30702",
            "41c2001d640546679abad1e6dd4af760",
            "0bbce800fabc4988b393dd241aed679e",
            "908c69f4a15941869582c9f4ad1334da"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "074ceb970ad64440b732c71c7499b899"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we show how a hugging-face DatasetDict is modelized. When we run the cell below we see that a hugging-face DatasetDict is a data structure close to a python dictionary. The raw_datasets DatasetDict has 3 sub-datasets: train, test and unsupervised. The unsupervised dataset is the union of train and test datasets.<br>\n",
        "To access the movies reviews from the training dataset, we have to run raw_datasets['train']['text']. To get the labels of the training dataset we run raw_datasets['train']['label']"
      ],
      "metadata": {
        "id": "l-VvOg7hbaVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets"
      ],
      "metadata": {
        "trusted": true,
        "id": "KJUu-rkDbaV0",
        "outputId": "0fa9d7b0-c4cc-4098-f1b4-3ffc7c5c5f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_datasets['train']['text'][0:1][0][0:170])\n",
        "print(raw_datasets['train']['text'][1:2][0][0:170])"
      ],
      "metadata": {
        "trusted": true,
        "id": "51Iyu2qJbaV1",
        "outputId": "774cd9bb-810e-4801-9a9b-464bcbb26f67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was s\n",
            "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train']['label'][0:2]"
      ],
      "metadata": {
        "trusted": true,
        "id": "cL5V-6cebaV2",
        "outputId": "cea2d022-c770-4d42-8052-87e1de35420a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "long_text = [len(x) for x in raw_datasets['train']['text']]"
      ],
      "metadata": {
        "trusted": true,
        "id": "YMVqXQsrbaV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess/Tokenize a hugging-face dataset\n",
        "Remind the goal of this notebook is to fin-tuned a Bert cased model. To preprocess our data, we will need a tokenizer. A tokenizer splits the data in tokens (these can be characters, words, part of words). For this task, we are using the tokenizer from the pre-trained model we selected (bert-base-cased)."
      ],
      "metadata": {
        "id": "W7oRqDZ1baV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZPW-S70LbaV6",
        "outputId": "ee53dfcc-699d-4dfd-9cb0-a1470d144187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "38eaafe06c2a4a57b1c77fcef71aa5bd",
            "ad964dfac1724ed298dcbcdbd8e893a7",
            "b6ead70dd2014796a165df5ba1d19392",
            "e3dcc6f77b6547e4a8d3a66a215191be",
            "1fee7919d3c04991b50c9ed15660caac",
            "af789af462d9488c8552e5689aeb8022",
            "d37870a5198945fca2b94dbeb488ea5b",
            "2b41115514934624bce5fa1eaf24db49",
            "c0bc507fb2094f4698472197cb7d141a",
            "6f2a808abe904d3bb8b9f3cbfbee0d0e",
            "c93adf60344b45e9ba5e1323fa059daf"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-53fb83ab475c4e81.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-492a91c24db1e8a9.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38eaafe06c2a4a57b1c77fcef71aa5bd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most importants features made during the tokenize step  are 'attention_mask', 'input_ids', 'label', 'token_type_ids'. Now, we don't need the text feature anymore. As a consequence, We remove the text columns from the huggingface dataset later in this notebook."
      ],
      "metadata": {
        "id": "zdRYpAZFbaV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "#tokenized_datasets"
      ],
      "metadata": {
        "trusted": true,
        "id": "oKByQ06gbaV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning the hugging-face bert-case model with tensorflow"
      ],
      "metadata": {
        "id": "F1gl_4o7baV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making the dataset usable by a tensorflow model\n",
        "* First step: we define the content of the training set and the test set.\n",
        "* Second step: Second step: we make these 2 datasets compatibles with tensorflow \n",
        "* Third step: we make the training and test dataset suitables for a tensorflow model"
      ],
      "metadata": {
        "id": "FK_lWkOEbaV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_dataset = tokenized_datasets[\"train\"]\n",
        "full_test_dataset = tokenized_datasets[\"test\"]\n",
        "full_train_dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "xBbuhbAnbaWB",
        "outputId": "7e65c4f2-8f8c-4266-f99f-221e2d0f7b5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 25000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second step: Second step: we make these 2 datasets compatibles with tensorflow\n",
        "tf_train_dataset = full_train_dataset.with_format(\"tensorflow\")\n",
        "tf_test_dataset = full_test_dataset.with_format(\"tensorflow\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "tAPsMy7EbaWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take a look at tf_train_dataset['input_ids']. It is tf.Tensor of shape=(25000, 512)"
      ],
      "metadata": {
        "id": "Uc2BbzEK1oyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_dataset['input_ids']"
      ],
      "metadata": {
        "id": "9wawJG0t2Uci",
        "outputId": "e3fb8ecb-6193-4233-cf51-66f122e8b47d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 512), dtype=int64, numpy=\n",
              "array([[  101,   146, 12765, ...,     0,     0,     0],\n",
              "       [  101,   107,   146, ...,     0,     0,     0],\n",
              "       [  101,  1409,  1178, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  1188,  1273, ...,     0,     0,     0],\n",
              "       [  101,   112,  1109, ...,  7880, 13225,   102],\n",
              "       [  101,  1109,  1642, ...,     0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take a look at tf_train_dataset['attention_mask']. It is also a tf.Tensor of shape=(25000,512)."
      ],
      "metadata": {
        "id": "pKAv5GCd2fEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_dataset['attention_mask']"
      ],
      "metadata": {
        "id": "t_EcD1iZ2piy",
        "outputId": "972299d7-f6a2-4679-ffcd-7e2721ff1988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 512), dtype=int64, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 0, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Third step: we make the training and test dataset suitables for a tensorflow model\n",
        "import tensorflow as tf\n",
        "train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
        "train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_train_dataset[\"label\"]))\n",
        "train_tf_dataset = train_tf_dataset.shuffle(len(tf_train_dataset)).batch(8)\n",
        "\n",
        "test_features = {x: tf_test_dataset[x] for x in tokenizer.model_input_names}\n",
        "test_tf_dataset = tf.data.Dataset.from_tensor_slices((test_features, tf_test_dataset[\"label\"]))\n",
        "test_tf_dataset = test_tf_dataset.batch(8)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6iyRO2_HbaWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we see how train_tf_dataset looks like:"
      ],
      "metadata": {
        "id": "4Ogp0PnK32EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(train_tf_dataset.as_numpy_iterator())[0:2]"
      ],
      "metadata": {
        "id": "-voQGVQH35ak",
        "outputId": "8ac06039-1552-46ce-cb8b-bb3fd7802dbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'input_ids': array([[ 101, 1188, 1108, ...,    0,    0,    0],\n",
              "          [ 101, 1130, 2030, ...,    0,    0,    0],\n",
              "          [ 101,  146, 1294, ...,    0,    0,    0],\n",
              "          ...,\n",
              "          [ 101,  146, 1309, ...,    0,    0,    0],\n",
              "          [ 101, 1752, 1104, ..., 2934, 1139,  102],\n",
              "          [ 101,  146, 1145, ...,    0,    0,    0]]),\n",
              "   'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]]),\n",
              "   'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 1, 1, 1],\n",
              "          [1, 1, 1, ..., 0, 0, 0]])},\n",
              "  array([1, 0, 0, 0, 0, 1, 1, 1])),\n",
              " ({'input_ids': array([[  101,   146,  3535, ...,     0,     0,     0],\n",
              "          [  101,  1274,   112, ...,     0,     0,     0],\n",
              "          [  101,  1157,  1632, ...,     0,     0,     0],\n",
              "          ...,\n",
              "          [  101,  1335,  1655, ...,     0,     0,     0],\n",
              "          [  101, 11281,  6603, ...,     0,     0,     0],\n",
              "          [  101,   146,  4819, ...,   179, 15932,   102]]),\n",
              "   'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]]),\n",
              "   'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 1, 1, 1]])},\n",
              "  array([1, 0, 1, 0, 1, 0, 1, 0]))]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We import the tensorflow pretrained bert-base-cased model from the huggingface hub.\n",
        "We import the pretrained bert-base-cased model from the huggingface hub. The model we will import is paired with the tokenizer we imported earlier in this notebook. We import the bert-base-cased in the cell below. We set num_labels=2 because we have 2 distincts values in the label columns from our dataset. In the cell below, model is a tensorflow model."
      ],
      "metadata": {
        "id": "QKGe5MzLbaWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers\n",
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "LciVrC62baWH",
        "outputId": "99caef10-453a-4e68-d8b1-da19a30310b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We fine-tune the pretrained model\n",
        "We compile the tensorflow model as we always do when we use tensorflow. Here we use the\n",
        "* the adam  optimizer with learning_rate=5e-5\n",
        "* SparseCategoricalCrossentropy loss fucntion\n",
        "* SparseCategoricalAccuracy() metrics\n",
        "\n",
        "To fine-tune properly a tensorflow hugging-face model with an adam optimizer, it recomded to set the leraning_rate to 5e-5."
      ],
      "metadata": {
        "id": "vPpEuGQobaWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
        ")\n",
        "\n",
        "model.fit(train_tf_dataset, validation_data=test_tf_dataset, epochs=2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "63hMMlBibaWJ",
        "outputId": "3ef210c7-5c74-4b27-b4fc-19ec2c448fd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "3125/3125 [==============================] - 4092s 1s/step - loss: 0.2990 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.2335 - val_sparse_categorical_accuracy: 0.9049\n",
            "Epoch 2/2\n",
            "3125/3125 [==============================] - 4072s 1s/step - loss: 0.2019 - sparse_categorical_accuracy: 0.9231 - val_loss: 0.2356 - val_sparse_categorical_accuracy: 0.9048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0978d291c0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the compile step, model is a fine-tuned transformer model. Then, we can apply model on a new movie review."
      ],
      "metadata": {
        "id": "AzgDLtJ3baWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_movie_review = [\"I was extraordinarily impressed by this film. It's one of the best sports films \\\n",
        "                    I've every seen. The visuals in this film are outstanding. I love the sequences \\\n",
        "                    in which the camer tracks the ball as it flies through the air or into the cup. \\\n",
        "                    The film moves well, offering both excitement and drama. The cinematography was fantastic.\\\n",
        "                    <br /><br />The acting performances are great. I was surprised by young Shia LaBeouf.\\\n",
        "                    He does well in this role. Stephen Dillane is also good as the brooding Harry Vardon. \\\n",
        "                    Peter Firth, Justin Ashforth, and Elias Koteas offer able support. \\\n",
        "                    The film is gripping and entertaining and for the first time in my \\\n",
        "                    life actually made me want to watch a golf tournament.\"]"
      ],
      "metadata": {
        "trusted": true,
        "id": "HYF0yRIAbaWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to apply the model to the new review, We have to:\n",
        "* vectorize the new movie review\n",
        "* put the vectorized text into a tf.data.Dataset\n",
        "* to apply the .batch(1) method to make review_data suitable for the fine-tuned model."
      ],
      "metadata": {
        "id": "tO0Dp-HqbaWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we vectorize\n",
        "token_new_review = tokenizer(new_movie_review, padding=\"max_length\", truncation=True)\n",
        "\n",
        "#put the vectorized text into a tf.data.Dataset\n",
        "import tensorflow as tf\n",
        "review_data = tf.data.Dataset.from_tensor_slices((dict(token_new_review)))\n",
        "\n",
        "#make review_data suitable for the fine-tuned model.\n",
        "review_data_batch = review_data.batch(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "31FgUMeRbaWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can apply the fine-tuned model to review_data_batch. Then, we apply a softmax function to the result to get a probability vector."
      ],
      "metadata": {
        "id": "TzQlgf2NbaWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "review_sentiment = ['negatif review','positif review']\n",
        "\n",
        "#we apply the fine-tuned model to review_data_batch\n",
        "pred = model.predict(review_data_batch).logits\n",
        "#we apply a sofmax function to get a probability vector\n",
        "prob_vector = tf.nn.softmax(pred, axis=1).numpy()\n",
        "prob_vector"
      ],
      "metadata": {
        "trusted": true,
        "id": "K6AO3H92baWO",
        "outputId": "f67c83ea-3a24-49d8-84eb-f22090d3f32f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00323815, 0.9967618 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we display the predicted class of the new review"
      ],
      "metadata": {
        "id": "s3dkicTCbaWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "review_sentiment = ['negatif review','positif review']\n",
        "review_sentiment[np.argmax(prob_vector)]"
      ],
      "metadata": {
        "trusted": true,
        "id": "hz4wTEXBbaWP",
        "outputId": "b19af359-8401-4dbb-9520-888964d67f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positif review'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning in PyTorch with the Trainer API\n",
        "**In this section, we deal with a PyTorch pretrained huggingface transformer. You might need to restart your notebook at this stage to free some memory.**\n",
        "In order to use the hugging-face pytorch Trainer API, you have to set up WANDB_DISABLED to true. Wandb means weights & Biases integration.  We set WANDB_DISABLED to “true” to disable wandb entirely. "
      ],
      "metadata": {
        "id": "RL3kSuwObaWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T15:46:26.945187Z",
          "iopub.execute_input": "2021-11-04T15:46:26.945475Z",
          "iopub.status.idle": "2021-11-04T15:46:26.949546Z",
          "shell.execute_reply.started": "2021-11-04T15:46:26.945443Z",
          "shell.execute_reply": "2021-11-04T15:46:26.948375Z"
        },
        "trusted": true,
        "id": "p0YpEtDcbaWU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download the huggingface IMDB dataset:"
      ],
      "metadata": {
        "id": "NwQObmZJbaWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T15:46:29.599457Z",
          "iopub.execute_input": "2021-11-04T15:46:29.599889Z",
          "iopub.status.idle": "2021-11-04T15:46:31.154279Z",
          "shell.execute_reply.started": "2021-11-04T15:46:29.599851Z",
          "shell.execute_reply": "2021-11-04T15:46:31.153563Z"
        },
        "trusted": true,
        "id": "ZCycGAIJbaWW",
        "outputId": "1b04762b-d406-49f6-dd42-990f3a887d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8fa1670400394d019b76a536401a7a61",
            "f21d7097ab6a45c1a30b6beeaa3c8e2b",
            "8c5cc9de89a740bc9a1d3a40fe939424",
            "e8fdef4d003d4278aa578e02cfac75e9",
            "73fa95f2b134445cac806ddf7dde2c66",
            "5945a3b9765245e990f0d0452e4f5079",
            "9cc8e2400a374d1b90f82feef8135a5b",
            "95d5cb66521746b5a62b2d1159ca0933",
            "170d94f26688439eaebafd7200dbc319",
            "307772fd1a1a4049b86704be6af91b5f",
            "842913374af5461a9cebc50fea3dd7bd"
          ]
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fa1670400394d019b76a536401a7a61"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We vectorize the movie reviews with a bert-case- tokenizer. Then we create the training dataset and the test dataset.**<br> In the cell , full train_dataset and full_text dataset are 2 huggingface datasets."
      ],
      "metadata": {
        "id": "mj5-CLWTbaWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "full_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(5000))\n",
        "full_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(3000))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T15:46:35.863716Z",
          "iopub.execute_input": "2021-11-04T15:46:35.864286Z",
          "iopub.status.idle": "2021-11-04T15:47:58.211784Z",
          "shell.execute_reply.started": "2021-11-04T15:46:35.864248Z",
          "shell.execute_reply": "2021-11-04T15:47:58.211039Z"
        },
        "trusted": true,
        "id": "8l300wlfbaWX",
        "outputId": "ab9a40fc-13e6-4467-ef2c-389577e2f1a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-53fb83ab475c4e81.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-492a91c24db1e8a9.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-976bf6a832514f5d.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-8a276681bb88a0b5.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-0e67510c8492afbf.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, in order to fine-tune a bert huggingface model with the trainer API,\n",
        "* We have to load the transfromer model we want to use. \n",
        "* We have to set the TrainingArguments\n",
        "* We set the Trainer\n",
        "\n",
        "The model we load is paired with the tokenizer we loaded earlier in this exemple. The model in the cell below is a Pytorch model. In the case of a pretrained pytorch model we use AutoModelForSequenceClassification instead of TFAutoModelForSequenceClassification.  "
      ],
      "metadata": {
        "id": "rO3W8x02baWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We load the transfromer model we want to use**<br>\n",
        "In the cell below, model is a PyTorch model."
      ],
      "metadata": {
        "id": "5rqkhi4obaWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "pytorch_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T15:49:07.933993Z",
          "iopub.execute_input": "2021-11-04T15:49:07.934796Z",
          "iopub.status.idle": "2021-11-04T15:49:10.333776Z",
          "shell.execute_reply.started": "2021-11-04T15:49:07.934738Z",
          "shell.execute_reply": "2021-11-04T15:49:10.333011Z"
        },
        "trusted": true,
        "id": "kfd6FMAkbaWe",
        "outputId": "759f878b-fb4f-4bc7-97e6-5f590faf6b91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We set the TrainingArguments**<br>\n",
        "The Trainer API uses some training arguments we call with a TrainingArguments object. You can use the default configuration with TrainingArguments(\"test_trainer\"). Else, you can set some arguments such that:\n",
        "* output_dir='./results',     the output directory\n",
        "* num_train_epochs the total number of training epochs\n",
        "* per_device_train_batch_size the batch size per device during training\n",
        "* per_device_eval_batch_size=20 the batch size for evaluation\n",
        "* weight_decay=0.01 the strength of weight decay\n",
        "* logging_dir='./logs' the directory for storing logs"
      ],
      "metadata": {
        "id": "kA_I3n2vbaWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We set some arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        ")"
      ],
      "metadata": {
        "id": "gdhI2XNkbaWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we use the default configuration. We change the number of epochs to 1\n",
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\"test_trainer\")\n",
        "training_args.num_train_epochs = 1\n",
        "training_args.per_device_eval_batch_size = 2\n",
        "training_args.per_device_train_batch_size = 2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T15:49:21.592064Z",
          "iopub.execute_input": "2021-11-04T15:49:21.592884Z",
          "iopub.status.idle": "2021-11-04T15:49:21.648374Z",
          "shell.execute_reply.started": "2021-11-04T15:49:21.592835Z",
          "shell.execute_reply": "2021-11-04T15:49:21.647636Z"
        },
        "trusted": true,
        "id": "R4-t7KGxbaWi",
        "outputId": "b9d913ec-33cd-4f38-9591-488830533a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We set the Trainer and begin the training stage with Trainer.train().**<br>\n",
        "The Trainer object takes some arguments such that:\n",
        "* model : a huggingface pretrained PyTorch model\n",
        "* args : a TrainingArguments defined earlier \n",
        "* train_dataset : a huggingface dataset made from a huggingface tokenizer step  \n",
        "* eval_datase : a huggingface dataset made from a huggingface tokenizer step\n",
        "\n",
        "The target value of a huggingface dataset used by the Trainer should always be named label else the Train API doesn't work."
      ],
      "metadata": {
        "id": "wiaJDRAMbaWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=pytorch_model, args=training_args, train_dataset=full_train_dataset)\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T15:49:28.709915Z",
          "iopub.execute_input": "2021-11-04T15:49:28.710594Z",
          "iopub.status.idle": "2021-11-04T16:58:50.348165Z",
          "shell.execute_reply.started": "2021-11-04T15:49:28.710554Z",
          "shell.execute_reply": "2021-11-04T16:58:50.346663Z"
        },
        "trusted": true,
        "id": "ZTwD6K7rbaWl",
        "outputId": "a4ec1a66-59b6-4ba9-9534-d8673478f0ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-236a61e39535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpytorch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_model_on_device\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             )\n\u001b[1;32m   1681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    983\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    984\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 14.76 GiB total capacity; 375.38 MiB already allocated; 9.75 MiB free; 408.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the Trainer step, pytorch_model is a fine-tuned transformer model. Then, we can apply pytorch_model on a new movie review. We have to\n",
        "* vectorize the new movie review\n",
        "* Apply the pytorch on the vectorized new text \n",
        "* use softmax function to get a PyTorch tensor probability vector\n",
        "* convert the previous PyTorch tensor into a numpy array"
      ],
      "metadata": {
        "id": "59TRb4ycbaWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_movie_review = [\"I was extraordinarily impressed by this film. It's one of the best sports films \\\n",
        "                    I've every seen. The visuals in this film are outstanding. I love the sequences \\\n",
        "                    in which the camer tracks the ball as it flies through the air or into the cup. \\\n",
        "                    The film moves well, offering both excitement and drama. The cinematography was fantastic.\\\n",
        "                    <br /><br />The acting performances are great. I was surprised by young Shia LaBeouf.\\\n",
        "                    He does well in this role. Stephen Dillane is also good as the brooding Harry Vardon. \\\n",
        "                    Peter Firth, Justin Ashforth, and Elias Koteas offer able support. \\\n",
        "                    The film is gripping and entertaining and for the first time in my \\\n",
        "                    life actually made me want to watch a golf tournament.\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T17:03:11.685229Z",
          "iopub.execute_input": "2021-11-04T17:03:11.685848Z",
          "iopub.status.idle": "2021-11-04T17:03:11.691661Z",
          "shell.execute_reply.started": "2021-11-04T17:03:11.685808Z",
          "shell.execute_reply": "2021-11-04T17:03:11.690861Z"
        },
        "trusted": true,
        "id": "DPr9ehb3baWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CUDA** (or Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing unit (GPU) for general purpose processing. **To(\"cuda\") in tokenizer step means we put the vectorized text in the GPU memory.**"
      ],
      "metadata": {
        "id": "wUaFyLJGbaWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we vectorize the new movie review\n",
        "review_token =tokenizer(new_movie_review, padding=\"max_length\", truncation=True,return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "#get a PyTorch tensor probability vector\n",
        "prob_pytorch_tensor = pytorch_model(**review_token )[0].softmax(1)\n",
        "\n",
        "#convert the previous PyTorch tensor into a numpy array\n",
        "prob_numpy_array = prob_pytorch_tensor.cpu().detach().numpy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T17:04:44.563041Z",
          "iopub.execute_input": "2021-11-04T17:04:44.563758Z",
          "iopub.status.idle": "2021-11-04T17:04:44.597777Z",
          "shell.execute_reply.started": "2021-11-04T17:04:44.563723Z",
          "shell.execute_reply": "2021-11-04T17:04:44.597086Z"
        },
        "trusted": true,
        "id": "ZF0uJhIvbaWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we display the predicted class of the new review"
      ],
      "metadata": {
        "id": "Q56ELsNIbaWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "review_sentiment = ['negatif review','positif review']\n",
        "review_sentiment[np.argmax(prob_numpy_array)]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-04T17:04:51.096027Z",
          "iopub.execute_input": "2021-11-04T17:04:51.096316Z",
          "iopub.status.idle": "2021-11-04T17:04:51.102843Z",
          "shell.execute_reply.started": "2021-11-04T17:04:51.096287Z",
          "shell.execute_reply": "2021-11-04T17:04:51.102015Z"
        },
        "trusted": true,
        "id": "Uxl_MFfWbaWr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}