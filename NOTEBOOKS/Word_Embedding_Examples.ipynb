{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embedding Examples.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvWzwDCEGWzl+v2jp9bsvc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabnancyuhp/DEEP-LEARNING/blob/main/NOTEBOOKS/Word_Embedding_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZoAD79TyLd2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example : Word vectorization with tf.keras embedding layer\n",
        "We load the dataset we'll use to compute the word embedding. We lowercase, remove the digits and remove the punctuations.\n",
        "https://orbifold.net/default/embedding-and-tokenizer-in-keras/<br>\n",
        "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
      ],
      "metadata": {
        "id": "n4bg-cs-LfmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/fabnancyuhp/DEEP-LEARNING/main/DATA/text_for_embedding.parquet.brotli\"\n",
        "text_for_embedding = pd.read_parquet(url)\n",
        "\n",
        "import re\n",
        "def preprocess_text(x):\n",
        "    punct_tag=re.compile(r'[^\\w\\s]')\n",
        "    new_text=punct_tag.sub(r'',x)\n",
        "    new_text = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , new_text)\n",
        "    new_text = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", new_text)\n",
        "    new_text = re.sub(r'[0-9]', '', new_text)\n",
        "    return(new_text.lower())\n",
        "\n",
        "text_for_embedding['text'] = text_for_embedding['text'].apply(lambda x:preprocess_text(x))\n",
        "text_for_embedding.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "WGTJW5dkLghP",
        "outputId": "65b485fe-2d26-41a8-83c6-a01c0c2949c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb594306-7d2b-4262-8e9b-a5e3a22f158d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12775</th>\n",
              "      <td>1</td>\n",
              "      <td>common sense is prevailing in brexit negotiati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>1</td>\n",
              "      <td>paul manafort the indicted former campaign man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4467</th>\n",
              "      <td>1</td>\n",
              "      <td>us representative mark walker said after a mee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb594306-7d2b-4262-8e9b-a5e3a22f158d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb594306-7d2b-4262-8e9b-a5e3a22f158d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb594306-7d2b-4262-8e9b-a5e3a22f158d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       class                                               text\n",
              "12775      1  common sense is prevailing in brexit negotiati...\n",
              "930        1  paul manafort the indicted former campaign man...\n",
              "4467       1  us representative mark walker said after a mee..."
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Tokenize object form tensorflow.keras.preprocessing.text. We transform each text in text_for_embedding['text'] to a sequence of integers. "
      ],
      "metadata": {
        "id": "XkiNjNVvLrrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "X = [text.split() for text in  list(text_for_embedding['text'])]\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "eYEoLqqOLl4Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4bnP9MKRLyHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "#encoded_review = [one_hot(d,vocab_size) for d in list(text_for_embedding['text'])]\n",
        "\n",
        "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#X_pad = pad_sequences(encoded_review,maxlen=1000,padding='post')"
      ],
      "metadata": {
        "id": "Vv_-i6YaLyd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer object creates a word index dictionary. We search the integer associated with the famous automakers gm and peugeot."
      ],
      "metadata": {
        "id": "8_Hpzqi_L86u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index['gm'])\n",
        "print(tokenizer.word_index['peugeot'])\n",
        "print(tokenizer.word_index['handsome'])\n",
        "#one_hot('gm peugeot gm',vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a87XW6wL9qV",
        "outputId": "30a77d7f-8b5f-4c16-c679-7412988dde97"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8807\n",
            "43318\n",
            "21452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retain 1000 words per text using pad_sequence object:"
      ],
      "metadata": {
        "id": "Dbm2Gq8yMIP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "X_pad = pad_sequences(X_seq,maxlen=1000,padding='post')\n",
        "X_pad[0][0:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1PdiSKPMCpd",
        "outputId": "7f0f0f5b-824e-4e04-d78b-7cf2a3666933"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1163,  1283,    11, 12303,     6,  1082,  1193], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We build a model to predict class from the text. After the neural network is trained we will get word embeddings as a side effect. So the problem for predict the class is almost like a fake problem. In fact we care about word embeddings. In the ANN we use to make word vectorization, we put an Embedding layer called \"embedding\"."
      ],
      "metadata": {
        "id": "34HuRfL2MSKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "embeded_vector_size = 15\n",
        "max_length = 1000\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,embeded_vector_size,input_length=max_length,name=\"embedding\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['binary_crossentropy'])"
      ],
      "metadata": {
        "id": "UY98cEtiMS2q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = text_for_embedding['class'].values\n",
        "model.fit(X_pad,Y,epochs=15)"
      ],
      "metadata": {
        "id": "Enlaarm7MZO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get the Embedding matrix produced by our model:"
      ],
      "metadata": {
        "id": "u6el8d9KMiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)+1\n",
        "Embedding_matrix = model.get_layer('embedding').get_weights()[0]\n",
        "\n",
        "Embedding_matrix.shape,len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "hfT_n8NLMi3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row of Embedding Matrix corresponds to a word from tokenizer.word_index. Below, we make a dictionary with words encountered in the corpus and their related vectorizations."
      ],
      "metadata": {
        "id": "8wvwjBSIMsWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_embeding = dict([(word,Embedding_matrix[tokenizer.word_index[word]]) for word in tokenizer.word_index.keys()])"
      ],
      "metadata": {
        "id": "qcOQXUXBMwH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_embeding['car']"
      ],
      "metadata": {
        "id": "iBG6rONEM2BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_embeding['automobile']"
      ],
      "metadata": {
        "id": "Qhqr69X8M46v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "distance.cosine(car, auto)"
      ],
      "metadata": {
        "id": "Wel3sBcfM8uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example : Word2Vec with gensim\n",
        "We use the Corpus from the previous example."
      ],
      "metadata": {
        "id": "vj60fL-yNGp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus = text_for_embedding['text']"
      ],
      "metadata": {
        "id": "xpYAsJ6tNB4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2vec is an unsupervised learning algorithm. In contrary to the above example, we don't need the class to make our words vectorization. The input of the word2vect algorithm is the corpus. We convert each words into a 100 dimentional vector."
      ],
      "metadata": {
        "id": "GO145WI7NM_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "X = [d.split() for d in text_for_embedding['text'].tolist()]\n",
        "DIM = 100\n",
        "\n",
        "#w2v_model = gensim.models.Word2Vec(sentences = X,vector_size=DIM,window=10,min_count=1)\n",
        "w2v_model = gensim.models.Word2Vec(sentences = X,size=DIM,window=10,min_count=1)"
      ],
      "metadata": {
        "id": "EtWwxxxPNTBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vocabulary size is given by len(w2v_model.wv). The vector representation of the word car is given by w2v_model.wv.get_vector(\"car\", norm=True) or by w2v_model.wv.get_vector(\"car\")."
      ],
      "metadata": {
        "id": "LoWfrp4KNew3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Vocabulary size: \"+str(len(w2v_model.wv)))\n",
        "print(\"The vector representation of the word car: \")\n",
        "w2v_model.wv.get_vector(\"car\")[0:10] "
      ],
      "metadata": {
        "id": "-SK0CllTNffQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NRyPolOTNkHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most similar word to France is w2v_model.wv.most_similar(\"france\")"
      ],
      "metadata": {
        "id": "mhXcYiJ7NkbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(\"france\")[0:3]"
      ],
      "metadata": {
        "id": "L4i7-a5ENn3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.get_vector(\"automobile\")[0:10] "
      ],
      "metadata": {
        "id": "NMKar1LRNrpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the cosinus distance between car and automobile."
      ],
      "metadata": {
        "id": "WAJAEq3SNwHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "distance.cosine(w2v_model.wv.get_vector(\"automobile\"), w2v_model.wv.get_vector(\"car\"))"
      ],
      "metadata": {
        "id": "e0JsKfOqNwdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the cosinus distance between friut and orange."
      ],
      "metadata": {
        "id": "QS7EmyzbN78i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "distance.cosine(w2v_model.wv.get_vector(\"fruit\"), w2v_model.wv.get_vector(\"orange\"))"
      ],
      "metadata": {
        "id": "T2b96NO4N8ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example : pretrained glove embedding"
      ],
      "metadata": {
        "id": "yzbcZuoxOHMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://nlp.stanford.edu/data/glove.42B.300d.zip\"\n",
        "\n",
        "import requests, io, zipfile\n",
        "filename = \"glove.42B.300d.txt\"\n",
        "#Remove \"blob\",  Replace github.com by raw.githubusercontent.com\n",
        "#url = \"https://raw.githubusercontent.com/fabnancyuhp/DEEP-LEARNING/main/DATA/superconduct.zip\"\n",
        "r = requests.get(url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))"
      ],
      "metadata": {
        "id": "8q52GbxQOHfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embeddings_index = dict()\n",
        "f = z.open('glove.42B.300d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0].decode(\"utf-8\")\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "metadata": {
        "id": "Jr6SJUfVOPUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "lj7NAQGpOWhr",
        "outputId": "333f9ccd-6390-4d60-e2da-6a0cdc32d424"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5a0756b9be69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E2KDSsLEOXPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}