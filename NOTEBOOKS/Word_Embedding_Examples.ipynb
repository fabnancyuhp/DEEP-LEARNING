{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embedding Examples.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMv6x+QgI32V3704AhVkFuQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabnancyuhp/DEEP-LEARNING/blob/main/NOTEBOOKS/Word_Embedding_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example : Word vectorization with tf.keras embedding layer\n",
        "We load the dataset we'll use to compute the word embedding. We lowercase, remove the digits and remove the punctuations.\n"
      ],
      "metadata": {
        "id": "n4bg-cs-LfmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/fabnancyuhp/DEEP-LEARNING/main/DATA/text_for_embedding.parquet.brotli\"\n",
        "text_for_embedding = pd.read_parquet(url)\n",
        "\n",
        "import re\n",
        "def preprocess_text(x):\n",
        "    punct_tag=re.compile(r'[^\\w\\s]')\n",
        "    new_text=punct_tag.sub(r'',x)\n",
        "    new_text = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , new_text)\n",
        "    new_text = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", new_text)\n",
        "    new_text = re.sub(r'[0-9]', '', new_text)\n",
        "    return(new_text.lower())\n",
        "\n",
        "text_for_embedding['text'] = text_for_embedding['text'].apply(lambda x:preprocess_text(x))\n",
        "text_for_embedding = text_for_embedding.reset_index()\n",
        "text_for_embedding.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "WGTJW5dkLghP",
        "outputId": "c740c591-1f92-4086-bf11-f54959e1802b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  class                                               text\n",
              "0  12775      1  common sense is prevailing in brexit negotiati...\n",
              "1    930      1  paul manafort the indicted former campaign man...\n",
              "2   4467      1  us representative mark walker said after a mee..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdb23c2a-e41b-4e9b-ad79-f55b87cc2073\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12775</td>\n",
              "      <td>1</td>\n",
              "      <td>common sense is prevailing in brexit negotiati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>930</td>\n",
              "      <td>1</td>\n",
              "      <td>paul manafort the indicted former campaign man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4467</td>\n",
              "      <td>1</td>\n",
              "      <td>us representative mark walker said after a mee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdb23c2a-e41b-4e9b-ad79-f55b87cc2073')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdb23c2a-e41b-4e9b-ad79-f55b87cc2073 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdb23c2a-e41b-4e9b-ad79-f55b87cc2073');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Tokenize object form tensorflow.keras.preprocessing.text. We transform each text in text_for_embedding['text'] to a sequence of integers. "
      ],
      "metadata": {
        "id": "XkiNjNVvLrrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#X = [text.split() for text in  list(text_for_embedding['text'])]\n",
        "X = text_for_embedding['text'].to_numpy()\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "eYEoLqqOLl4Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "Vv_-i6YaLyd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer object creates a word index dictionary. We search the integer associated with the famous automakers gm and peugeot. We also display the vocabulary size of the corpus (text_for_embedding['text']). The words of the corpus are stored in word_index object with their associated number."
      ],
      "metadata": {
        "id": "8_Hpzqi_L86u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index['gm'])\n",
        "print(tokenizer.word_index['peugeot'])\n",
        "print(tokenizer.word_index['handsome'])\n",
        "print(\"vocab_size:\"+str(len(tokenizer.word_index)+1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a87XW6wL9qV",
        "outputId": "ddd68cf5-515f-4c64-b7fe-2125fc197bae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8813\n",
            "43337\n",
            "21466\n",
            "vocab_size:178373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we create a word sequence of the first sentence text_for_embedding['text'][0] and we compare it with X_seq[0]."
      ],
      "metadata": {
        "id": "R_WTmipxoWL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_for_embedding['text'][0])   \n",
        "print([tokenizer.word_index[word] for word in text_for_embedding['text'][0].split()][0:4])\n",
        "print(X_seq[0][0:4])"
      ],
      "metadata": {
        "id": "-L0mYhQkoU7W",
        "outputId": "ab57cc78-8ce0-47ae-c1f4-6f163e0571ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common sense is prevailing in brexit negotiations between britain and the european union france s foreign minister said on friday as he welcomed signs that talks were moving into a new phase after an initial breakthrough  the european commission said on friday enough progress had been made in brexit negotiations with britain and that a second phase of discussions should begin ending an impasse over the status of the irish border  the work that has been done on negotiations  is gradually leading us to common sense  jeanyves le drian told france inter radio  we wanted the conditions for britain s withdrawal to be clearly defined to be able to move into another phase that s what s going to happen now i hope\n",
            "[1162, 1285, 11, 12314]\n",
            "[1162, 1285, 11, 12314]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retain 1000 words per text using pad_sequence object:"
      ],
      "metadata": {
        "id": "Dbm2Gq8yMIP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "X_pad = pad_sequences(X_seq,maxlen=1000,padding='post')\n",
        "X_pad[0][0:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1PdiSKPMCpd",
        "outputId": "68e5566f-f23b-4c81-95e5-101b7963187d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1162,  1285,    11, 12314,     6,  1082,  1192], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We build a model to predict class from the text. After the neural network is trained we will get word embeddings as a side effect. So the problem for predict the class is almost like a fake problem. In fact we care about word embeddings. In the ANN we use to make word vectorization, we put an Embedding layer called \"embedding\". Each word of word_index is embedded in 15 sized dense vector."
      ],
      "metadata": {
        "id": "34HuRfL2MSKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "embeded_vector_size = 15\n",
        "max_length = 1000\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,embeded_vector_size,input_length=max_length,name=\"embedding\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['binary_crossentropy'])"
      ],
      "metadata": {
        "id": "UY98cEtiMS2q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = text_for_embedding['class'].values\n",
        "model.fit(X_pad,Y,epochs=15)"
      ],
      "metadata": {
        "id": "Enlaarm7MZO2",
        "outputId": "2ef1f748-56a1-4249-91f5-e24d4bef7e05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "969/969 [==============================] - 33s 33ms/step - loss: 0.1298 - binary_crossentropy: 0.1298\n",
            "Epoch 2/15\n",
            "969/969 [==============================] - 31s 33ms/step - loss: 0.0103 - binary_crossentropy: 0.0103\n",
            "Epoch 3/15\n",
            "969/969 [==============================] - 31s 32ms/step - loss: 0.0025 - binary_crossentropy: 0.0025\n",
            "Epoch 4/15\n",
            "969/969 [==============================] - 32s 33ms/step - loss: 9.1057e-04 - binary_crossentropy: 9.1057e-04\n",
            "Epoch 5/15\n",
            "969/969 [==============================] - 31s 32ms/step - loss: 3.8757e-04 - binary_crossentropy: 3.8757e-04\n",
            "Epoch 6/15\n",
            "969/969 [==============================] - 32s 33ms/step - loss: 1.9783e-04 - binary_crossentropy: 1.9783e-04\n",
            "Epoch 7/15\n",
            "969/969 [==============================] - 34s 35ms/step - loss: 1.0821e-04 - binary_crossentropy: 1.0821e-04\n",
            "Epoch 8/15\n",
            "969/969 [==============================] - 31s 32ms/step - loss: 6.2433e-05 - binary_crossentropy: 6.2433e-05\n",
            "Epoch 9/15\n",
            "969/969 [==============================] - 31s 33ms/step - loss: 3.3242e-05 - binary_crossentropy: 3.3242e-05\n",
            "Epoch 10/15\n",
            "969/969 [==============================] - 32s 33ms/step - loss: 2.0056e-05 - binary_crossentropy: 2.0056e-05\n",
            "Epoch 11/15\n",
            "969/969 [==============================] - 32s 33ms/step - loss: 1.1196e-05 - binary_crossentropy: 1.1196e-05\n",
            "Epoch 12/15\n",
            "969/969 [==============================] - 32s 33ms/step - loss: 6.6331e-06 - binary_crossentropy: 6.6331e-06\n",
            "Epoch 13/15\n",
            "969/969 [==============================] - 32s 33ms/step - loss: 3.8863e-06 - binary_crossentropy: 3.8863e-06\n",
            "Epoch 14/15\n",
            "969/969 [==============================] - 32s 33ms/step - loss: 2.3652e-06 - binary_crossentropy: 2.3652e-06\n",
            "Epoch 15/15\n",
            "969/969 [==============================] - 34s 35ms/step - loss: 1.4419e-06 - binary_crossentropy: 1.4419e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70d6c2cdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get the Embedding matrix produced by our model:"
      ],
      "metadata": {
        "id": "u6el8d9KMiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)+1\n",
        "Embedding_matrix = model.get_layer('embedding').get_weights()[0]\n",
        "\n",
        "Embedding_matrix.shape,len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "hfT_n8NLMi3x",
        "outputId": "4bceaa77-725e-4c6f-8395-1c73cdc2eb61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((178373, 15), 178373)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row of Embedding Matrix corresponds to a word from tokenizer.word_index. Below, we make a dictionary with words encountered in the corpus and their related vectorizations."
      ],
      "metadata": {
        "id": "8wvwjBSIMsWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_embeding = dict([(word,Embedding_matrix[tokenizer.word_index[word]]) for word in tokenizer.word_index.keys()])"
      ],
      "metadata": {
        "id": "qcOQXUXBMwH_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_embeding['car']"
      ],
      "metadata": {
        "id": "iBG6rONEM2BI",
        "outputId": "1b71002d-0be9-4a55-abc0-f2e822d70ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.06600994,  0.02541907, -0.02483669,  0.0974196 ,  0.07336339,\n",
              "       -0.02285413,  0.11127128,  0.01865002, -0.08324052,  0.00216753,\n",
              "        0.15210138, -0.111652  , -0.03299259,  0.06876224, -0.06726278],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_embeding['automobile']"
      ],
      "metadata": {
        "id": "pEas3QF0v65q",
        "outputId": "7edc6664-9e75-40d8-c810-ac7eda34761a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.41754709e-02, -1.14046864e-01,  3.99329215e-02, -7.66363591e-02,\n",
              "       -7.85041898e-02,  1.10874735e-01, -1.17618717e-01, -4.69670035e-02,\n",
              "        1.41314939e-02, -8.44414309e-02, -8.52738619e-02,  7.90638998e-02,\n",
              "       -6.32217125e-05, -7.66031295e-02,  1.01314396e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the cosine distance between the car vector and automobile vector:"
      ],
      "metadata": {
        "id": "V8vdDAJnwO2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "distance.cosine(dict_embeding['car'], dict_embeding['automobile'])"
      ],
      "metadata": {
        "id": "Wel3sBcfM8uW",
        "outputId": "c0414fe3-d291-471a-cb5f-3c7f9a00b800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.781082808971405"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example : Word2Vec with gensim\n",
        "We use the Corpus from the previous example."
      ],
      "metadata": {
        "id": "vj60fL-yNGp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus = text_for_embedding['text']"
      ],
      "metadata": {
        "id": "xpYAsJ6tNB4i"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2vec is an unsupervised learning algorithm. In contrary to the above example, we don't need the class to make our words vectorization. The input of the word2vect algorithm is the corpus. We convert each words into a 100 dimentional vector."
      ],
      "metadata": {
        "id": "GO145WI7NM_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "X = [d.split() for d in text_for_embedding['text'].tolist()]\n",
        "DIM = 100\n",
        "\n",
        "#w2v_model = gensim.models.Word2Vec(sentences = X,vector_size=DIM,window=10,min_count=1)\n",
        "w2v_model = gensim.models.Word2Vec(sentences = X,size=DIM,window=10,min_count=1)"
      ],
      "metadata": {
        "id": "EtWwxxxPNTBl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vocabulary size is given by len(w2v_model.wv). The vector representation of the word car is given by w2v_model.wv.get_vector(\"car\", norm=True) or by w2v_model.wv.get_vector(\"car\")."
      ],
      "metadata": {
        "id": "LoWfrp4KNew3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Vocabulary size: \"+str(len(w2v_model.wv)))\n",
        "print(\"The vector representation of the word car: \")\n",
        "w2v_model.wv.get_vector(\"car\")[0:10] "
      ],
      "metadata": {
        "id": "-SK0CllTNffQ",
        "outputId": "83d78077-f274-4133-df21-d6c6d5ed7e87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vector representation of the word car: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.533081 , -3.367085 , -0.4285773,  2.5477087, -2.9588268,\n",
              "       -0.4585598, -0.7733542,  2.5632012,  4.073978 , -4.035179 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most similar word to France is w2v_model.wv.most_similar(\"france\")"
      ],
      "metadata": {
        "id": "mhXcYiJ7NkbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(\"france\")[0:3]"
      ],
      "metadata": {
        "id": "L4i7-a5ENn3J",
        "outputId": "2d7a9edd-4a3a-4600-d135-30563f16e738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('italy', 0.8047981858253479),\n",
              " ('germany', 0.7870280742645264),\n",
              " ('netherlands', 0.766010046005249)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.get_vector(\"automobile\")[0:10] "
      ],
      "metadata": {
        "id": "NMKar1LRNrpz",
        "outputId": "5706e25f-6550-41a1-bcf9-0fa32ce5acd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.22998844,  0.5625361 ,  0.3646414 ,  0.22749312,  0.09547658,\n",
              "        0.32680476, -0.10790078,  0.4935212 ,  0.17794877,  0.1389324 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the cosinus distance between car and automobile."
      ],
      "metadata": {
        "id": "WAJAEq3SNwHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "distance.cosine(w2v_model.wv.get_vector(\"automobile\"), w2v_model.wv.get_vector(\"car\"))"
      ],
      "metadata": {
        "id": "e0JsKfOqNwdz",
        "outputId": "e3370cb3-56b6-4f6e-fb82-ad11f6d33e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9186250045895576"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the cosinus distance between friut and orange."
      ],
      "metadata": {
        "id": "QS7EmyzbN78i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "distance.cosine(w2v_model.wv.get_vector(\"fruit\"), w2v_model.wv.get_vector(\"orange\"))"
      ],
      "metadata": {
        "id": "T2b96NO4N8ud",
        "outputId": "3d885953-8a6d-40c7-d9ad-5f4035e7b266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5883492529392242"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example : pretrained glove embedding\n",
        "In this case, the vectorization is already done. We just extract the vectors representations."
      ],
      "metadata": {
        "id": "yzbcZuoxOHMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://nlp.stanford.edu/data/glove.42B.300d.zip\"\n",
        "\n",
        "import requests, io, zipfile\n",
        "filename = \"glove.42B.300d.txt\"\n",
        "#Remove \"blob\",  Replace github.com by raw.githubusercontent.com\n",
        "#url = \"https://raw.githubusercontent.com/fabnancyuhp/DEEP-LEARNING/main/DATA/superconduct.zip\"\n",
        "r = requests.get(url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))"
      ],
      "metadata": {
        "id": "8q52GbxQOHfC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embeddings_index = dict()\n",
        "f = z.open('glove.42B.300d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0].decode(\"utf-8\")\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "metadata": {
        "id": "Jr6SJUfVOPUS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We display the vector of the word car and its shape"
      ],
      "metadata": {
        "id": "W7clsISHzqsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings_index['car'][0:20])\n",
        "print(str(embeddings_index['car'].shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2KDSsLEOXPK",
        "outputId": "12ce875c-4440-46e9-b838-e335121eaba7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.59128   -0.38927   -0.16089    0.043683  -0.43888    0.11397\n",
            " -2.9075     0.13149   -0.30903   -0.57064   -0.72339   -0.44372\n",
            " -0.12936   -0.32073    0.50047    0.47942   -0.43085    0.0043741\n",
            " -0.24877    0.35756  ]\n",
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the cosine distance between the car vector and automobile vector:"
      ],
      "metadata": {
        "id": "iRja3Fdt0Nxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#embeddings_index['automobile']\n",
        "from scipy.spatial import distance\n",
        "distance.cosine(embeddings_index['car'], embeddings_index['automobile'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhIv_W8MumJG",
        "outputId": "b4891487-2609-4f02-c11d-269c15403bb1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26692473888397217"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}