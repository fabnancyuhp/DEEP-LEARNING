{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabnancyuhp/DEEP-LEARNING/blob/main/NOTEBOOKS/simples-applications-of-recurrent-neural-networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "TsIx-R6acOfx"
      },
      "source": [
        "# Example : Gender Prediction by using names with LSTMs.\n",
        "In this example, we predict the gender of a name using an LSTM. LSTM stands Long short-term memory. LSTM is the most popular Recurrent Neural network. There is no duplicate in this database.  you have to import the data executing the cell below. There are 2 columns in this dataset : Name and Gender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:00:59.748001Z",
          "iopub.status.busy": "2021-11-18T09:00:59.747372Z",
          "iopub.status.idle": "2021-11-18T09:01:00.265913Z",
          "shell.execute_reply": "2021-11-18T09:01:00.264919Z",
          "shell.execute_reply.started": "2021-11-18T09:00:59.747844Z"
        },
        "trusted": true,
        "id": "9_wub4tdcOf2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/fabnancyuhp/DEEP-LEARNING/main/DATA/baby_names.csv\")\n",
        "data = data.sample(frac=1,random_state=1998)\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "FSQTV36lcOf6"
      },
      "source": [
        "**Fist step:** We convert the names in lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:01:34.317280Z",
          "iopub.status.busy": "2021-11-18T09:01:34.316667Z",
          "iopub.status.idle": "2021-11-18T09:01:34.410459Z",
          "shell.execute_reply": "2021-11-18T09:01:34.409090Z",
          "shell.execute_reply.started": "2021-11-18T09:01:34.317215Z"
        },
        "trusted": true,
        "id": "mbe1cVkmcOf8"
      },
      "outputs": [],
      "source": [
        "data['Name'] = data['Name'].apply(lambda x:x.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Ms1OxLrEcOf-"
      },
      "source": [
        "**Second step: encode the Gender.**<br>\n",
        "Since we want to predict the gender of name. For this purpose we have to encode the gender : 0 for F and 1 for M. To encode we can use labelencoder but in this notebook we encode with a shortcut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:01:39.660243Z",
          "iopub.status.busy": "2021-11-18T09:01:39.659927Z",
          "iopub.status.idle": "2021-11-18T09:01:39.964955Z",
          "shell.execute_reply": "2021-11-18T09:01:39.964134Z",
          "shell.execute_reply.started": "2021-11-18T09:01:39.660212Z"
        },
        "trusted": true,
        "id": "3bgNz72scOgA"
      },
      "outputs": [],
      "source": [
        "data['Gender'] = data.astype('category').Gender.cat.codes\n",
        "data.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "b3L02DXocOgB"
      },
      "source": [
        "**Third step : encode the letters of each name.**<br>\n",
        "Encode the letter of each name means we make a focus on the neural network input. When the LSTM deals with the name  Tauno using the  notations of the course, we have:\n",
        "* $X^{<1>}$ is a vector representation of the letter t\n",
        "* $X^{<2>}$ is a vector representation of the letter a\n",
        "* .... $X^{<5>}$ is vector representation of the letter o\n",
        "\n",
        "Now we have to encode the letters of each name. The above steps allow us to apply an embedding layer as a vector representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:01:45.673569Z",
          "iopub.status.busy": "2021-11-18T09:01:45.673244Z",
          "iopub.status.idle": "2021-11-18T09:01:46.002541Z",
          "shell.execute_reply": "2021-11-18T09:01:46.001359Z",
          "shell.execute_reply.started": "2021-11-18T09:01:45.673538Z"
        },
        "trusted": true,
        "id": "7UtgXuSvcOgE"
      },
      "outputs": [],
      "source": [
        "#we get the alphabet\n",
        "import string\n",
        "letters = list(string.ascii_lowercase)\n",
        "vocab = dict(zip(letters,range(1,27)))\n",
        "\n",
        "#we create the reverse vocabulary\n",
        "r_vocab = dict(zip(range(1,27),letters))\n",
        "\n",
        "def letter_to_number(nom):\n",
        "    return([vocab[l] for l in list(nom)])\n",
        "\n",
        "data['Name'] = data['Name'].apply(lambda x:letter_to_number(x))\n",
        "data.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:00:01.732408Z",
          "iopub.status.busy": "2021-11-16T16:00:01.732138Z",
          "iopub.status.idle": "2021-11-16T16:00:01.738078Z",
          "shell.execute_reply": "2021-11-16T16:00:01.737184Z",
          "shell.execute_reply.started": "2021-11-16T16:00:01.732381Z"
        },
        "trusted": true,
        "id": "IzZkfXb6cOgI"
      },
      "outputs": [],
      "source": [
        "print(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:00:06.611342Z",
          "iopub.status.busy": "2021-11-16T16:00:06.61056Z",
          "iopub.status.idle": "2021-11-16T16:00:06.617184Z",
          "shell.execute_reply": "2021-11-16T16:00:06.61618Z",
          "shell.execute_reply.started": "2021-11-16T16:00:06.611303Z"
        },
        "trusted": true,
        "id": "34-9SV9DcOgK"
      },
      "outputs": [],
      "source": [
        "letter_to_number('marc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lMFXM-rncOgL"
      },
      "source": [
        "Now, we notice the lengths of the encoded names are imbalanced. The input size of an LSTM should be constant. We build a histogram of the name length to visualize the size distribution of the names. We choose a maximum size of 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:00:08.15379Z",
          "iopub.status.busy": "2021-11-16T16:00:08.152955Z",
          "iopub.status.idle": "2021-11-16T16:00:08.999799Z",
          "shell.execute_reply": "2021-11-16T16:00:08.998915Z",
          "shell.execute_reply.started": "2021-11-16T16:00:08.15375Z"
        },
        "trusted": true,
        "id": "j8akRXqocOgN"
      },
      "outputs": [],
      "source": [
        "names_length = [len(nom) for nom in data['Name'].values]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(names_length,bins=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "itRDUZzocOgP"
      },
      "source": [
        "**Fourth step: Pad variable length sequences with 0 values.**<br>\n",
        "We want to make all the names list the same size using the Keras **pad_sequences** function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:01:53.641909Z",
          "iopub.status.busy": "2021-11-18T09:01:53.641583Z",
          "iopub.status.idle": "2021-11-18T09:02:00.243477Z",
          "shell.execute_reply": "2021-11-18T09:02:00.242259Z",
          "shell.execute_reply.started": "2021-11-18T09:01:53.641876Z"
        },
        "trusted": true,
        "id": "vQHewhPYcOgQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = pad_sequences(data['Name'].values,maxlen=10, padding='pre')\n",
        "X[0:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qsdpfb_hcOgS"
      },
      "source": [
        "**Fifth step: We create the target values Y.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:02:02.139708Z",
          "iopub.status.busy": "2021-11-18T09:02:02.139399Z",
          "iopub.status.idle": "2021-11-18T09:02:02.144880Z",
          "shell.execute_reply": "2021-11-18T09:02:02.143692Z",
          "shell.execute_reply.started": "2021-11-18T09:02:02.139675Z"
        },
        "trusted": true,
        "id": "uRGL5eLycOgU"
      },
      "outputs": [],
      "source": [
        "Y = data['Gender'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cFLziaZGcOgV"
      },
      "source": [
        "**Sixth step:** we split the X,Y into training set and test set using sklearn.model_selection.train_test_split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:02:05.756247Z",
          "iopub.status.busy": "2021-11-18T09:02:05.755937Z",
          "iopub.status.idle": "2021-11-18T09:02:06.436226Z",
          "shell.execute_reply": "2021-11-18T09:02:06.435264Z",
          "shell.execute_reply.started": "2021-11-18T09:02:05.756209Z"
        },
        "trusted": true,
        "id": "63_37tgRcOgW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "okVGcc6NcOgY"
      },
      "source": [
        "**Seventh step: We set up  3 differents LSTMs**\n",
        "* one with a single LSTM layer\n",
        "* one with 2 LSTM layers\n",
        "* one with a Bidirectional LSTM\n",
        "In this step, we compile and fit each model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "C38hvTCocOgZ"
      },
      "source": [
        "Here, we define a neural network with a single LSTM layer: \n",
        "* Since we use pad_sequences with a maxlen=10, the Input layer should have the shape=(10,) earlier in this example.\n",
        "* The embedding layer produce outputs dense vectors with 5 components (output_dim=5)\n",
        "* Units=32 in the first LSTM layer means this layer outputs a 32 sized vector.\n",
        "\n",
        "input_dim in the Embedding Layer is the size of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:26:14.562084Z",
          "iopub.status.busy": "2021-11-16T16:26:14.561419Z",
          "iopub.status.idle": "2021-11-16T16:26:14.805615Z",
          "shell.execute_reply": "2021-11-16T16:26:14.80485Z",
          "shell.execute_reply.started": "2021-11-16T16:26:14.562036Z"
        },
        "trusted": true,
        "id": "YL0FjwZmcOga"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "vocabsize = len(vocab)+1\n",
        "\n",
        "LSTM_SINGLE = Sequential([Input(shape=(10,)),Embedding(input_dim=vocabsize,output_dim=5),\\\n",
        "                          LSTM(units=40),Dense(1,activation='sigmoid')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "execution": {
          "iopub.execute_input": "2021-11-16T16:00:29.227334Z",
          "iopub.status.busy": "2021-11-16T16:00:29.227053Z",
          "iopub.status.idle": "2021-11-16T16:00:29.23346Z",
          "shell.execute_reply": "2021-11-16T16:00:29.232707Z",
          "shell.execute_reply.started": "2021-11-16T16:00:29.227301Z"
        },
        "id": "GeGHqE_hcOgb"
      },
      "source": [
        "We compile the LSTM SINGLE model using an adam optimizer, a binary_crossentropy loss and we set metrics=['accuracy']. Then, we fit it with 20 epochs and batch_size=256."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:33:20.551154Z",
          "iopub.status.busy": "2021-11-16T16:33:20.550233Z",
          "iopub.status.idle": "2021-11-16T16:34:37.953302Z",
          "shell.execute_reply": "2021-11-16T16:34:37.95234Z",
          "shell.execute_reply.started": "2021-11-16T16:33:20.551089Z"
        },
        "trusted": true,
        "id": "6ZjT5skHcOgb"
      },
      "outputs": [],
      "source": [
        "LSTM_SINGLE.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "his = LSTM_SINGLE.fit(X_train,y_train,epochs=20,batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kwWNJVpicOgd"
      },
      "source": [
        "Now, we evaluate LSTM SINGLE on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:39:08.654571Z",
          "iopub.status.busy": "2021-11-16T16:39:08.654091Z",
          "iopub.status.idle": "2021-11-16T16:39:12.771104Z",
          "shell.execute_reply": "2021-11-16T16:39:12.770195Z",
          "shell.execute_reply.started": "2021-11-16T16:39:08.654533Z"
        },
        "trusted": true,
        "id": "HyvDJlehcOgd"
      },
      "outputs": [],
      "source": [
        "LSTM_SINGLE.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cnSoouKKcOge"
      },
      "source": [
        "Now, we create a neural network with 2 LSTM layers:\n",
        "* Since we use pad_sequences with a maxlen=10, the Input layer should have the shape=(10,) earlier in this example.\n",
        "* The embedding layer produce outputs dense vectors with 5 components (output_dim=5)\n",
        "* Units=32 in the first LSTM layer means this layer outputs a 32 sized vector. Since, we have a second LSTM layer, we should set return_sequences=True.\n",
        "* Units=64 in the first LSTM layer means this layer outputs a 64 sized vector\n",
        "* Since we solve a classification problem with 2 classes, the last layer is a dense layer with sigmoid activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:46:47.247149Z",
          "iopub.status.busy": "2021-11-16T16:46:47.246808Z",
          "iopub.status.idle": "2021-11-16T16:46:47.724436Z",
          "shell.execute_reply": "2021-11-16T16:46:47.723673Z",
          "shell.execute_reply.started": "2021-11-16T16:46:47.247107Z"
        },
        "trusted": true,
        "id": "zQRuy3-acOgf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "vocabsize = len(vocab)+1\n",
        "\n",
        "LSTM_TWO_LSTM = Sequential([Input(shape=(10,)),Embedding(input_dim=vocabsize,output_dim=5),\\\n",
        "                            LSTM(units=32,return_sequences=True),LSTM(units=64),\\\n",
        "                            Dense(1,activation='sigmoid')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CW_qBryQcOgg"
      },
      "source": [
        "We compile the LSTM SINGLE model using an adam optimizer, a binary_crossentropy loss and we set metrics=['accuracy']. Then, we fit it with 15 epochs and batch_size=256."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:48:49.618591Z",
          "iopub.status.busy": "2021-11-16T16:48:49.618076Z",
          "iopub.status.idle": "2021-11-16T16:50:56.329265Z",
          "shell.execute_reply": "2021-11-16T16:50:56.328293Z",
          "shell.execute_reply.started": "2021-11-16T16:48:49.61856Z"
        },
        "trusted": true,
        "id": "xKhbqL56cOgh"
      },
      "outputs": [],
      "source": [
        "LSTM_TWO_LSTM.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "his = LSTM_TWO_LSTM.fit(X_train,y_train,epochs=15,batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LMogHjBCcOgh"
      },
      "source": [
        "Here, we define a neural network with a single bidirectional LSTM layer: \n",
        "* Since we use pad_sequences with a maxlen=10, the Input layer should have the shape=(10,) earlier in this example.\n",
        "* The embedding layer produce outputs dense vectors with 5 components (output_dim=5)\n",
        "* Units=32 in the first LSTM layer means this layer outputs a 32 sized vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:02:20.315987Z",
          "iopub.status.busy": "2021-11-18T09:02:20.315461Z",
          "iopub.status.idle": "2021-11-18T09:02:20.978048Z",
          "shell.execute_reply": "2021-11-18T09:02:20.977129Z",
          "shell.execute_reply.started": "2021-11-18T09:02:20.315951Z"
        },
        "trusted": true,
        "id": "9B8SGuPDcOgi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Input, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "vocabsize = len(vocab)+1\n",
        "\n",
        "NAME_BIDIRECT = Sequential([Input(shape=(20,)),Embedding(input_dim=vocabsize,output_dim=5),\\\n",
        "                           Bidirectional(LSTM(units=32)),Dense(1,activation='sigmoid')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-18T09:03:51.782532Z",
          "iopub.status.busy": "2021-11-18T09:03:51.782183Z",
          "iopub.status.idle": "2021-11-18T09:05:16.472703Z",
          "shell.execute_reply": "2021-11-18T09:05:16.471984Z",
          "shell.execute_reply.started": "2021-11-18T09:03:51.782499Z"
        },
        "trusted": true,
        "id": "4gfKHutjcOgj"
      },
      "outputs": [],
      "source": [
        "NAME_BIDIRECT.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "his = NAME_BIDIRECT.fit(X_train,y_train,epochs=15,batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OF5Ez5p7cOgk"
      },
      "source": [
        "**Eighth step : we use the model LSTM_SINGLE to predict the gender of new names.**<br>\n",
        "We test LSTM_SINGLE model with some new names. mmy_model.predict returns the probability of the tested name is masculine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T16:56:28.059303Z",
          "iopub.status.busy": "2021-11-16T16:56:28.058932Z",
          "iopub.status.idle": "2021-11-16T16:56:28.692347Z",
          "shell.execute_reply": "2021-11-16T16:56:28.691504Z",
          "shell.execute_reply.started": "2021-11-16T16:56:28.059266Z"
        },
        "trusted": true,
        "id": "xJpHeyI5cOgk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "def input_name_to_test(nom):\n",
        "    new_nom=nom.lower()\n",
        "    new_nom=[vocab[l] for l in list(new_nom)]\n",
        "    new_nom=pad_sequences(np.array([new_nom]),maxlen=10, padding='pre')\n",
        "    probability_masc = LSTM_SINGLE.predict(new_nom)\n",
        "    if probability_masc<0.5:\n",
        "        print(nom+\" is probably a feminine name\")\n",
        "    else:\n",
        "        print(nom+\" is probably a masculine name\")\n",
        "    return(probability_masc)\n",
        "\n",
        "input_name_to_test('Linda'), input_name_to_test('Brian'), input_name_to_test('Fabien')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "bVHQNRBHcOgl"
      },
      "source": [
        "# Exercice : Country prediction of cities\n",
        "In this exercice, our goal is to predict the country of cities from France, Germany and Italy. Run, the cell below to create the database of cities names. In this database, there are 2 columns : Country, City. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:26:36.364071Z",
          "iopub.status.busy": "2021-11-17T13:26:36.363406Z",
          "iopub.status.idle": "2021-11-17T13:26:37.068827Z",
          "shell.execute_reply": "2021-11-17T13:26:37.068006Z",
          "shell.execute_reply.started": "2021-11-17T13:26:36.364034Z"
        },
        "trusted": true,
        "id": "WhwPMHuNcOgm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file = \"https://raw.githubusercontent.com/fabnancyuhp/DEEP-LEARNING/main/DATA/citie_fr_ge_it.csv\"\n",
        "world_cities_fr_ge_it = pd.read_csv(file,compression='zip')\n",
        "world_cities_fr_ge_it = world_cities_fr_ge_it.loc[world_cities_fr_ge_it['Country']\\\n",
        "                                                  .isin(['fr','ge','it'])][['Country','City','AccentCity']]\\\n",
        "                                                  .drop_duplicates(subset=['Country','City','AccentCity']).reset_index()\n",
        "\n",
        "fr = world_cities_fr_ge_it.loc[world_cities_fr_ge_it['Country']=='fr'].sample(n=20000)\n",
        "ge = world_cities_fr_ge_it.loc[world_cities_fr_ge_it['Country']=='ge']\n",
        "it = world_cities_fr_ge_it.loc[world_cities_fr_ge_it['Country']=='it']\n",
        "world_cities_fr_ge_it = pd.concat([fr,ge,it],axis=0).sample(frac=1)[['Country','City']]\n",
        "world_cities_fr_ge_it.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "89ytt4XLcOgn"
      },
      "source": [
        "1) Remove the blanks of the City column. You can use the function below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:28:05.246687Z",
          "iopub.status.busy": "2021-11-17T13:28:05.246154Z",
          "iopub.status.idle": "2021-11-17T13:28:05.254143Z",
          "shell.execute_reply": "2021-11-17T13:28:05.253593Z",
          "shell.execute_reply.started": "2021-11-17T13:28:05.246654Z"
        },
        "trusted": true,
        "id": "PSi_nduDcOgo"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "letters = list(string.ascii_lowercase)\n",
        "def remove_non_lettre(ville):\n",
        "    hh = list(ville)\n",
        "    hhbis = [lettre for lettre in hh if lettre in letters]\n",
        "    hhbis = \"\".join(hhbis)\n",
        "    return(hhbis)\n",
        "remove_non_lettre('saint-martin-de-bromes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:28:12.711338Z",
          "iopub.status.busy": "2021-11-17T13:28:12.710544Z",
          "iopub.status.idle": "2021-11-17T13:28:12.966653Z",
          "shell.execute_reply": "2021-11-17T13:28:12.965755Z",
          "shell.execute_reply.started": "2021-11-17T13:28:12.711304Z"
        },
        "trusted": true,
        "id": "3TGyQGrncOgo"
      },
      "outputs": [],
      "source": [
        "#Your code here : \n",
        "world_cities_fr_ge_it['City'] = #complete the code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "z-Oebw2FcOgp"
      },
      "source": [
        "2) Encode the Country column using LabelEncoder from the sklearn library. Store the result in a new column named Country_encode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:28:18.437813Z",
          "iopub.status.busy": "2021-11-17T13:28:18.4375Z",
          "iopub.status.idle": "2021-11-17T13:28:19.189625Z",
          "shell.execute_reply": "2021-11-17T13:28:19.188958Z",
          "shell.execute_reply.started": "2021-11-17T13:28:18.43778Z"
        },
        "trusted": true,
        "id": "TPDvEu4qcOgq"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(world_cities_fr_ge_it['Country'].unique())\n",
        "\n",
        "world_cities_fr_ge_it['Country_encode'] = #complete the code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vTyVCnNdcOgr"
      },
      "source": [
        "3) Encode the letters of cities names from the City column. Read the third step in the above example. Store the result in a new column called City_code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:28:24.533666Z",
          "iopub.status.busy": "2021-11-17T13:28:24.532927Z",
          "iopub.status.idle": "2021-11-17T13:28:24.804085Z",
          "shell.execute_reply": "2021-11-17T13:28:24.803144Z",
          "shell.execute_reply.started": "2021-11-17T13:28:24.53363Z"
        },
        "trusted": true,
        "id": "itqBPaNhcOgr"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "letters = list(string.ascii_lowercase)\n",
        "vocab = dict(zip(letters,range(1,27)))\n",
        "\n",
        "def letter_to_number(nom):\n",
        "    return([vocab[l] for l in list(nom)])\n",
        "\n",
        "world_cities_fr_ge_it['City_code'] = #your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "D3mr5KrWcOgs"
      },
      "source": [
        "4) The lengths of the encoded cities names are not constant. We have to make all encoded cities names the same size. For this purpose we have to use pad_sequences from tensorflow.keras library like it is done in the fourth step in the above example. Apply pad_sequences to world_cities_fr_ge_it['City_code'] with max_len=20 and padding='pre'. Store the result in X."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:28:34.751934Z",
          "iopub.status.busy": "2021-11-17T13:28:34.751613Z",
          "iopub.status.idle": "2021-11-17T13:28:35.119832Z",
          "shell.execute_reply": "2021-11-17T13:28:35.119004Z",
          "shell.execute_reply.started": "2021-11-17T13:28:34.751894Z"
        },
        "trusted": true,
        "id": "xTHJ3wWqcOgs"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "X = #complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jGx8l7wZcOgt"
      },
      "source": [
        "5) In this question we create the target value Y. Remember, we have 3 classes encoded in the question 2. Create the target value Y using to_categorical from the tensorflow.keras library and world cities_fr_ge_it['Country_code'] you created in question 2. **to_categorical**  converts a class vector (integers) to binary class matrix (see the example below):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:30:03.005831Z",
          "iopub.status.busy": "2021-11-17T13:30:03.00547Z",
          "iopub.status.idle": "2021-11-17T13:30:03.015262Z",
          "shell.execute_reply": "2021-11-17T13:30:03.014256Z",
          "shell.execute_reply.started": "2021-11-17T13:30:03.005786Z"
        },
        "trusted": true,
        "id": "QDPGRbwTcOgu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "classe_vectore = [0, 1, 2, 3]\n",
        "binary_class_matrix= to_categorical(classe_vectore,num_classes=4)\n",
        "binary_class_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:30:06.298784Z",
          "iopub.status.busy": "2021-11-17T13:30:06.298464Z",
          "iopub.status.idle": "2021-11-17T13:30:06.304842Z",
          "shell.execute_reply": "2021-11-17T13:30:06.303963Z",
          "shell.execute_reply.started": "2021-11-17T13:30:06.29875Z"
        },
        "trusted": true,
        "id": "T-_wWEIucOgv"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "Y = #your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "zCtNkiDicOgx"
      },
      "source": [
        "6) Create the train set and the test set from X (created in question 4) and Y (created in question 5). For this purpose apply train_test_split from the sklearn package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:30:09.785508Z",
          "iopub.status.busy": "2021-11-17T13:30:09.785087Z",
          "iopub.status.idle": "2021-11-17T13:30:09.850438Z",
          "shell.execute_reply": "2021-11-17T13:30:09.849594Z",
          "shell.execute_reply.started": "2021-11-17T13:30:09.785478Z"
        },
        "trusted": true,
        "id": "J9uHNdRZcOgy"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = #your code here "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "HUCWNLpAcOgy"
      },
      "source": [
        "7) In this question we Build a model with a single LSTM layer to predict the country of a city name. Build a neural network with the following layers:\n",
        "* an Input layer\n",
        "* an Embedding layer that output a 6 sized vector\n",
        "* a LSTM layer with 42 units\n",
        "* a Dense layer\n",
        "\n",
        "Call this model city_single. Compile this model with an adam optimizer and the accuracy metric. Fit it with 10 epochs using X_train and y_train. Evaluate this model on X_test and y_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:32:02.912082Z",
          "iopub.status.busy": "2021-11-17T13:32:02.911779Z",
          "iopub.status.idle": "2021-11-17T13:34:33.998511Z",
          "shell.execute_reply": "2021-11-17T13:34:33.997946Z",
          "shell.execute_reply.started": "2021-11-17T13:32:02.912048Z"
        },
        "trusted": true,
        "id": "0hDNNuJ7cOgz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, BatchNormalization, LSTM, Input, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "vocabsize = len(vocab)+1\n",
        "\n",
        "city_single = #your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7OinU-CLcOg0"
      },
      "source": [
        "8) Use city_single to predict the country of dijon, baressa, chvrnisi. \n",
        "* The function handle_city_name return the padded encoding of a city name. \n",
        "* city_single.predict return a probability vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T14:40:20.077003Z",
          "iopub.status.busy": "2021-11-17T14:40:20.076695Z",
          "iopub.status.idle": "2021-11-17T14:40:20.086287Z",
          "shell.execute_reply": "2021-11-17T14:40:20.085613Z",
          "shell.execute_reply.started": "2021-11-17T14:40:20.076946Z"
        },
        "trusted": true,
        "id": "OHyLHGiycOg1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def  handle_city_name(cityname):\n",
        "    name = remove_non_lettre(cityname)\n",
        "    name = letter_to_number(name)\n",
        "    name = pad_sequences(np.array([name]),maxlen=20, padding='pre')\n",
        "    return(name)\n",
        "\n",
        "handle_city_name('dijon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcqPYVs0cOg1"
      },
      "outputs": [],
      "source": [
        "city_single.predict(handle_city_name('dijon'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T14:45:06.823862Z",
          "iopub.status.busy": "2021-11-17T14:45:06.82356Z",
          "iopub.status.idle": "2021-11-17T14:45:07.392226Z",
          "shell.execute_reply": "2021-11-17T14:45:07.391596Z",
          "shell.execute_reply.started": "2021-11-17T14:45:06.823828Z"
        },
        "trusted": true,
        "id": "aH9xdE8tcOg2"
      },
      "outputs": [],
      "source": [
        "#your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QnaN52MGcOg3"
      },
      "source": [
        "9) In this question we build a model with a 2 LSTM layers to predict the country of a city name. Build a neural network with the following layers:\n",
        "* an Input layer\n",
        "* an Embedding layer that output a 6 sized vector\n",
        "* a LSTM layer with 30 units. You have to set return_sequences=True\n",
        "* a dropout layer with rate=0.2\n",
        "* a LSTM layer with 60 units.\n",
        "* a Dense layer\n",
        "\n",
        "Call this model city_double. Compile this model with an adam optimizer and the accuracy metric. Fit it with 10 epochs using X_train and y_train. Evaluate this model on X_test and y_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T13:57:02.886071Z",
          "iopub.status.busy": "2021-11-17T13:57:02.884727Z",
          "iopub.status.idle": "2021-11-17T14:00:18.829457Z",
          "shell.execute_reply": "2021-11-17T14:00:18.828476Z",
          "shell.execute_reply.started": "2021-11-17T13:57:02.88599Z"
        },
        "trusted": true,
        "id": "QUxN7tAtcOg3"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, LSTM, Input, Embedding, Dropout\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "vocabsize = len(vocab)+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "M7J_l4EmcOg4"
      },
      "source": [
        "10) Build a model with a bidirectional LSTM layer to predict the country of a city. Call this model city_bidirect. Compile this model with an adam optimizer and the accuracy metric. Fit it with 10 epochs using X_train and y_train. Evaluate this model on X_test and y_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-17T14:07:56.738933Z",
          "iopub.status.busy": "2021-11-17T14:07:56.738586Z",
          "iopub.status.idle": "2021-11-17T14:12:34.177051Z",
          "shell.execute_reply": "2021-11-17T14:12:34.176042Z",
          "shell.execute_reply.started": "2021-11-17T14:07:56.738895Z"
        },
        "trusted": true,
        "id": "mafRdndOcOg5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, BatchNormalization, LSTM, Input, Embedding, Bidirectional\n",
        "from tensorflow.keras import Sequential"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (system-wide)",
      "language": "python",
      "metadata": {
        "cocalc": {
          "description": "Python 3 programming language",
          "priority": 100,
          "url": "https://www.python.org/"
        }
      },
      "name": "python3",
      "resource_dir": "/ext/jupyter/kernels/python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "simples-applications-of-recurrent-neural-networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}