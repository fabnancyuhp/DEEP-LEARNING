{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f374f14872154d46b34a683bd0b23ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b0f0163a9dd4e01892032e73e7f1a37",
              "IPY_MODEL_612abf28aab1450885425ae2c48bd23d",
              "IPY_MODEL_753ad18ba1704c569f112d00591ff435"
            ],
            "layout": "IPY_MODEL_61d4ad73a0e84ad0a4182d86f3997532"
          }
        },
        "3b0f0163a9dd4e01892032e73e7f1a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1f80c466f4416b99f21495de11ea94",
            "placeholder": "​",
            "style": "IPY_MODEL_0448ffcfbd86482e83e6d18169cba842",
            "value": "Downloading: 100%"
          }
        },
        "612abf28aab1450885425ae2c48bd23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5890bf8260f4c9280b5910e6647cfa0",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8a67f9534a642318cb84c8b94fbebb4",
            "value": 267967963
          }
        },
        "753ad18ba1704c569f112d00591ff435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97bdb667925c4dc88bcd869cc7e2fd90",
            "placeholder": "​",
            "style": "IPY_MODEL_24921a6a0e1b46d89a12845de9613c09",
            "value": " 268M/268M [00:03&lt;00:00, 73.4MB/s]"
          }
        },
        "61d4ad73a0e84ad0a4182d86f3997532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1f80c466f4416b99f21495de11ea94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0448ffcfbd86482e83e6d18169cba842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5890bf8260f4c9280b5910e6647cfa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a67f9534a642318cb84c8b94fbebb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97bdb667925c4dc88bcd869cc7e2fd90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24921a6a0e1b46d89a12845de9613c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabnancyuhp/DEEP-LEARNING/blob/main/NOTEBOOKS/fine-tuning-in-pytorch-with-the-trainer-api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning in PyTorch with the Trainer API\n",
        "This notebook is inspired by https://huggingface.co/blog/sentiment-analysis-python. In this notebook, we deal with a PyTorch pretrained hugging-face transformer. More precisely, we use a distilbert transformer over the IMDB dataset.<br> \n",
        "DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.<br>\n",
        "The goal is to make a model that predict weather a movie review is positive or not."
      ],
      "metadata": {
        "id": "eDqZpo0OqFq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download the huggingface IMDB dataset. full_train_dataset and full_test_dataset are hugging-face datasets objects."
      ],
      "metadata": {
        "id": "iu3hNvtGqFrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets\n",
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"imdb\")\n",
        "\n",
        "full_train_dataset = raw_datasets[\"train\"].shuffle(seed=42).select([i for i in list(range(3000))])\n",
        "full_test_dataset = raw_datasets[\"test\"].shuffle(seed=42).select([i for i in list(range(300))])\n",
        "\n",
        "import gc\n",
        "del raw_datasets\n",
        "gc.collect()\n",
        "\n",
        "#full_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(5000))\n",
        "#full_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(3000))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-27T15:17:50.742784Z",
          "iopub.execute_input": "2022-12-27T15:17:50.743149Z",
          "iopub.status.idle": "2022-12-27T15:18:24.016333Z",
          "shell.execute_reply.started": "2022-12-27T15:17:50.743116Z",
          "shell.execute_reply": "2022-12-27T15:18:24.015104Z"
        },
        "trusted": true,
        "id": "0H9ROaBOqFrC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We vectorize the movie reviews with a distilbert-base-uncased tokenizer. Then we create the training dataset and the test dataset.\n",
        " In the cell , full_train_dataset and full_test_dataset are 2 huggingface datasets."
      ],
      "metadata": {
        "id": "o0MOeTW6qFrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "full_train_dataset = full_train_dataset.map(tokenize_function, batched=True)\n",
        "full_test_dataset = full_test_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-27T15:18:24.021494Z",
          "iopub.execute_input": "2022-12-27T15:18:24.022314Z",
          "iopub.status.idle": "2022-12-27T15:18:32.015816Z",
          "shell.execute_reply.started": "2022-12-27T15:18:24.022278Z",
          "shell.execute_reply": "2022-12-27T15:18:32.014684Z"
        },
        "trusted": true,
        "id": "LojTA12GqFrD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, in order to fine-tune a bert huggingface model with the trainer API,\n",
        "* We have to load the transfromer model we want to use. \n",
        "* We have to set the TrainingArguments\n",
        "* We set the Trainer\n",
        "\n",
        "The model we load is paired with the tokenizer we loaded earlier in this exemple. The model in the cell below is a Pytorch model. In the case of a pretrained pytorch model we use AutoModelForSequenceClassification instead of TFAutoModelForSequenceClassification.  "
      ],
      "metadata": {
        "id": "kbWyfzfZqFrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We load the distilbert-base-uncased transfromer we want to use\n",
        "In the cell below, model is a PyTorch hugging-face model. The goal is to make a model that predict weather a movie review is positive or not. Then, we 2 classes in our problem and we choose num_labels=2 when we load the distilbert transformer. "
      ],
      "metadata": {
        "id": "TC-FeIeyqFrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "#pytorch_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "pytorch_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-27T15:18:39.608955Z",
          "iopub.execute_input": "2022-12-27T15:18:39.609680Z",
          "iopub.status.idle": "2022-12-27T15:18:50.410590Z",
          "shell.execute_reply.started": "2022-12-27T15:18:39.609645Z",
          "shell.execute_reply": "2022-12-27T15:18:50.409605Z"
        },
        "trusted": true,
        "id": "Jm2uBuaLqFrF",
        "outputId": "f23ecbb9-3405-48ef-e8ef-9c06e8d59b36",
        "colab": {
          "referenced_widgets": [
            "f374f14872154d46b34a683bd0b23ca4",
            "3b0f0163a9dd4e01892032e73e7f1a37",
            "612abf28aab1450885425ae2c48bd23d",
            "753ad18ba1704c569f112d00591ff435",
            "61d4ad73a0e84ad0a4182d86f3997532",
            "7e1f80c466f4416b99f21495de11ea94",
            "0448ffcfbd86482e83e6d18169cba842",
            "d5890bf8260f4c9280b5910e6647cfa0",
            "d8a67f9534a642318cb84c8b94fbebb4",
            "97bdb667925c4dc88bcd869cc7e2fd90",
            "24921a6a0e1b46d89a12845de9613c09"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f374f14872154d46b34a683bd0b23ca4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We set the TrainingArguments**<br>\n",
        "The Trainer API uses some training arguments we call with a TrainingArguments object. You can use the default configuration with TrainingArguments(\"test_trainer\"). Else, you can set some arguments such that:\n",
        "\n",
        "```python\n",
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        ")\n",
        "```\n",
        "We use the default configuration with TrainingArguments(\"test_trainer\"):"
      ],
      "metadata": {
        "id": "Awqu4XEtqFrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\"test_trainer\")\n",
        "training_args.num_train_epochs = 2\n",
        "#training_args.per_device_eval_batch_size = 2\n",
        "#training_args.per_device_train_batch_size = 2\n",
        "#training_args"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-27T15:20:42.141502Z",
          "iopub.execute_input": "2022-12-27T15:20:42.141852Z",
          "iopub.status.idle": "2022-12-27T15:20:46.252641Z",
          "shell.execute_reply.started": "2022-12-27T15:20:42.141821Z",
          "shell.execute_reply": "2022-12-27T15:20:46.251669Z"
        },
        "trusted": true,
        "id": "6_2NPljcqFrG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We set the Trainer and begin the training stage with Trainer.train().**<br>\n",
        "The Trainer object takes some arguments such that:\n",
        "* model : a huggingface pretrained PyTorch model\n",
        "* args : a TrainingArguments defined earlier \n",
        "* train_dataset : a huggingface dataset made from a huggingface tokenizer step  \n",
        "* eval_datase : a huggingface dataset made from a huggingface tokenizer step\n",
        "\n",
        "The target value of a huggingface dataset used by the Trainer should always be named label else the Train API doesn't work."
      ],
      "metadata": {
        "id": "f-yYanrfqFrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=pytorch_model, args=training_args, train_dataset=full_train_dataset)\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-27T15:22:05.228298Z",
          "iopub.execute_input": "2022-12-27T15:22:05.228648Z",
          "iopub.status.idle": "2022-12-27T15:26:13.644982Z",
          "shell.execute_reply.started": "2022-12-27T15:22:05.228617Z",
          "shell.execute_reply": "2022-12-27T15:26:13.644060Z"
        },
        "trusted": true,
        "id": "tzSeT0b5qFrH",
        "outputId": "ece36bd9-0a94-449c-aed0-bccc33270212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3000\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 750\n",
            "  Number of trainable parameters = 66955010\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 04:54, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.358700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to test_trainer/checkpoint-500\n",
            "Configuration saved in test_trainer/checkpoint-500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=750, training_loss=0.29596461486816406, metrics={'train_runtime': 298.6867, 'train_samples_per_second': 20.088, 'train_steps_per_second': 2.511, 'total_flos': 794804391936000.0, 'train_loss': 0.29596461486816406, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After the Trainer step, pytorch_model is a fine-tuned transformer model. Then, we can apply pytorch_model on a new movie review. \n",
        "We have to\n",
        "* vectorize the new movie review\n",
        "* Apply the pytorch on the vectorized new text \n",
        "* use softmax function to get a PyTorch tensor probability vector\n",
        "* convert the previous PyTorch tensor into a numpy array"
      ],
      "metadata": {
        "id": "wSDkaVkMqFrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_movie_review = [\"I was extraordinarily impressed by this film. It's one of the best sports films \\\n",
        "                    I've every seen. The visuals in this film are outstanding. I love the sequences \\\n",
        "                    in which the camer tracks the ball as it flies through the air or into the cup. \\\n",
        "                    The film moves well, offering both excitement and drama. The cinematography was fantastic.\\\n",
        "                    <br /><br />The acting performances are great. I was surprised by young Shia LaBeouf.\\\n",
        "                    He does well in this role. Stephen Dillane is also good as the brooding Harry Vardon. \\\n",
        "                    Peter Firth, Justin Ashforth, and Elias Koteas offer able support. \\\n",
        "                    The film is gripping and entertaining and for the first time in my \\\n",
        "                    life actually made me want to watch a golf tournament.\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-27T15:27:36.832223Z",
          "iopub.execute_input": "2022-12-27T15:27:36.832863Z",
          "iopub.status.idle": "2022-12-27T15:27:36.838436Z",
          "shell.execute_reply.started": "2022-12-27T15:27:36.832829Z",
          "shell.execute_reply": "2022-12-27T15:27:36.837061Z"
        },
        "trusted": true,
        "id": "ibAYZRvjqFrH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CUDA** (or Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing unit (GPU) for general purpose processing. **To(\"cuda\") in tokenizer step means we put the vectorized text in the GPU memory.**"
      ],
      "metadata": {
        "id": "dS4NQzKfqFrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we vectorize the new movie review\n",
        "review_token =tokenizer(new_movie_review, padding=\"max_length\", truncation=True,return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "#get a PyTorch tensor probability vector\n",
        "prob_pytorch_tensor = pytorch_model(**review_token )[0].softmax(1)\n",
        "\n",
        "#convert the previous PyTorch tensor into a numpy array\n",
        "prob_numpy_array = prob_pytorch_tensor.cpu().detach().numpy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-27T15:28:15.996965Z",
          "iopub.execute_input": "2022-12-27T15:28:15.997892Z",
          "iopub.status.idle": "2022-12-27T15:28:16.018642Z",
          "shell.execute_reply.started": "2022-12-27T15:28:15.997856Z",
          "shell.execute_reply": "2022-12-27T15:28:16.017706Z"
        },
        "trusted": true,
        "id": "QmtyOPgcqFrI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we display the predicted class of the new review"
      ],
      "metadata": {
        "id": "gcjgDM7VqFrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "review_sentiment = ['negatif review','positif review']\n",
        "review_sentiment[np.argmax(prob_numpy_array)]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-27T15:29:11.340423Z",
          "iopub.execute_input": "2022-12-27T15:29:11.340767Z",
          "iopub.status.idle": "2022-12-27T15:29:11.347999Z",
          "shell.execute_reply.started": "2022-12-27T15:29:11.340737Z",
          "shell.execute_reply": "2022-12-27T15:29:11.347071Z"
        },
        "trusted": true,
        "id": "_MnL99FhqFrI",
        "outputId": "fd6c257a-b66b-48bc-db5a-d36b3e552af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positif review'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}