{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabnancyuhp/DEEP-LEARNING/blob/main/NOTEBOOKS/exercice-emoji-prediction-student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "uO3dQJcya8rX"
      },
      "source": [
        "# Data cleaning functions\n",
        "\n",
        "here, we provide some useful functions to clean text data. You have to call these functions during preprocessing text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T14:36:35.010429Z",
          "iopub.status.busy": "2021-11-21T14:36:35.010049Z",
          "iopub.status.idle": "2021-11-21T14:36:35.019087Z",
          "shell.execute_reply": "2021-11-21T14:36:35.017703Z",
          "shell.execute_reply.started": "2021-11-21T14:36:35.010400Z"
        },
        "trusted": true,
        "id": "y4QXIf8Na8rd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "#Removes HTML syntaxes\n",
        "def remove_html(data):\n",
        "    html_tag=re.compile(r'<.*?>')\n",
        "    data=html_tag.sub(r'',data)\n",
        "    return data\n",
        "\n",
        "#Removes URL data\n",
        "def _remove_urls(x):\n",
        "    return re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , x)\n",
        "\n",
        "#Removes emails\n",
        "def _remove_emails(x):\n",
        "    return re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", x)\n",
        "\n",
        "def _remove_rt(x):\n",
        "    return re.sub(r'\\brt\\b', '', x).strip()\n",
        "\n",
        "def _remove_special_chars(x):\n",
        "    x = re.sub(r'[^\\w ]+', \"\", x)\n",
        "    x = ' '.join(x.split())\n",
        "    return x\n",
        "\n",
        "def remove_digit(x):\n",
        "    return re.sub(r'[0-9]', '', x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JtDnxCEga8rg"
      },
      "source": [
        "# Exercise: Emojis prediction\n",
        "Before doing this exercise, I recomand you to read carefully  the notebooks about RNN applications.\n",
        "* https://nbviewer.ipython.org/github/fabnancyuhp/DEEP-LEARNING/blob/main/NOTEBOOKS/text-mining-with-recurrent-neural-networks.ipynb\n",
        "* https://nbviewer.ipython.org/github/fabnancyuhp/DEEP-LEARNING/blob/main/NOTEBOOKS/simples-applications-of-recurrent-neural-networks.ipynb\n",
        "\n",
        "\n",
        "The goal of this exercise is to construct LSTM neural network to predict the emoji from tweets. In other words, given a tweet, we want to predict the emoji chosen by the author of the tweet. This exercise is a textmining problem close to sentiment analysis. You have to run the above cell \n",
        "* to import the data used for this exercise\n",
        "* to creat a python dictionary making a correspondance between numbers and emojis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:13:35.504320Z",
          "iopub.status.busy": "2021-11-21T15:13:35.503971Z",
          "iopub.status.idle": "2021-11-21T15:13:35.876930Z",
          "shell.execute_reply": "2021-11-21T15:13:35.875658Z",
          "shell.execute_reply.started": "2021-11-21T15:13:35.504289Z"
        },
        "trusted": true,
        "id": "UgqEoCP8a8ri",
        "outputId": "a0671c99-2b44-4bb3-a9f9-304e338909fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                TEXT emoji\n",
              "0  Vacation wasted ! #vacation2017 #photobomb #ti...     ðŸ˜œ\n",
              "1  Merry Christmas you filthy little animals. Wea...     ðŸŽ„\n",
              "2         Happy 4th ya'll! @ Sausalito, California\\n    ðŸ‡ºðŸ‡¸"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-510f704b-60f0-4bb7-993a-e51c0e1dd005\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT</th>\n",
              "      <th>emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vacation wasted ! #vacation2017 #photobomb #ti...</td>\n",
              "      <td>ðŸ˜œ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Merry Christmas you filthy little animals. Wea...</td>\n",
              "      <td>ðŸŽ„</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Happy 4th ya'll! @ Sausalito, California\\n</td>\n",
              "      <td>ðŸ‡ºðŸ‡¸</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-510f704b-60f0-4bb7-993a-e51c0e1dd005')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-510f704b-60f0-4bb7-993a-e51c0e1dd005 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-510f704b-60f0-4bb7-993a-e51c0e1dd005');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import requests, io, zipfile, pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "number_emoji = {0:'ðŸ‡ºðŸ‡¸',1:'ðŸŽ„',2:'ðŸ˜œ'}\n",
        "emoji_to_number = {'ðŸ‡ºðŸ‡¸':0,'ðŸŽ„':1,'ðŸ˜œ':2}\n",
        "\n",
        "fil=\"https://raw.githubusercontent.com/fabnancyuhp\\\n",
        "/DEEP-LEARNING/main/DATA/Twitter_emoji_simplified.csv\"\n",
        "\n",
        "tweet = pd.read_csv(fil)\n",
        "tweet = tweet[['TEXT','emoji']]\n",
        "tweet.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kWv88IFVa8rj"
      },
      "source": [
        "1/ How many distinct emojis does the tweet dataset have? Create a column tweet['class'] that encode tweet['emoji'] using emoji_to_number dictionary. Tweet['class'] will be the target values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:21:02.480753Z",
          "iopub.status.busy": "2021-11-21T15:21:02.480350Z",
          "iopub.status.idle": "2021-11-21T15:21:02.484976Z",
          "shell.execute_reply": "2021-11-21T15:21:02.483863Z",
          "shell.execute_reply.started": "2021-11-21T15:21:02.480718Z"
        },
        "trusted": true,
        "id": "nhdnmY2da8rk"
      },
      "outputs": [],
      "source": [
        "#distinct emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:31:02.521980Z",
          "iopub.status.busy": "2021-11-21T15:31:02.521421Z",
          "iopub.status.idle": "2021-11-21T15:31:02.531320Z",
          "shell.execute_reply": "2021-11-21T15:31:02.530197Z",
          "shell.execute_reply.started": "2021-11-21T15:31:02.521943Z"
        },
        "trusted": true,
        "id": "nXansuhka8rl"
      },
      "outputs": [],
      "source": [
        "#The emoji_to_number dictionary\n",
        "emoji_to_number = {'ðŸ‡ºðŸ‡¸':0,'ðŸŽ„':1,'ðŸ˜œ':2}\n",
        "\n",
        "#use a lambda function with emoji_to_number dictionary\n",
        "tweet['class']  = tweet['emoji'].apply(#lamnda function here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:31:11.049347Z",
          "iopub.status.busy": "2021-11-21T15:31:11.048793Z",
          "iopub.status.idle": "2021-11-21T15:31:11.189800Z",
          "shell.execute_reply": "2021-11-21T15:31:11.188800Z",
          "shell.execute_reply.started": "2021-11-21T15:31:11.049312Z"
        },
        "trusted": true,
        "id": "H4vp1eo_a8rn"
      },
      "outputs": [],
      "source": [
        "#Quick view of the class repartition\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "sns.countplot(x='class',data=tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OYvCPG-Za8ro"
      },
      "source": [
        "2/ Print the emoji and class of the row number 101 of the tweet dataset? hint : use pandas iloc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:22:47.392758Z",
          "iopub.status.busy": "2021-11-21T15:22:47.392233Z",
          "iopub.status.idle": "2021-11-21T15:22:47.397398Z",
          "shell.execute_reply": "2021-11-21T15:22:47.396658Z",
          "shell.execute_reply.started": "2021-11-21T15:22:47.392724Z"
        },
        "trusted": true,
        "id": "nahS_gVka8rq"
      },
      "outputs": [],
      "source": [
        "#Your answer here\n",
        "row_101 = tweet.iloc[101]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2q2zZ4dna8rr"
      },
      "source": [
        "3/ Make a word cloud with all tweets that have an emoji ðŸŽ„."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:31:26.307918Z",
          "iopub.status.busy": "2021-11-21T15:31:26.307476Z",
          "iopub.status.idle": "2021-11-21T15:31:30.223645Z",
          "shell.execute_reply": "2021-11-21T15:31:30.222860Z",
          "shell.execute_reply.started": "2021-11-21T15:31:26.307880Z"
        },
        "trusted": true,
        "id": "e7x3WZyha8rs"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "tweet_tree = tweet.loc[tweet['emoji']=='ðŸŽ„']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "FNnbJhrVa8rt"
      },
      "source": [
        "4/ The goal of this question is to clean the column tweet['TEXT']. For this purpose use sequentially the following functions we defined at the beginning of this notebook.\n",
        "* remove_html\n",
        "* _remove_urls\n",
        "* _remove_emails\n",
        "* _remove_rt\n",
        "* _remove_special_chars\n",
        "* remove_digit\n",
        "\n",
        "Convert Tweet['TEXT'] into lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:51:44.931391Z",
          "iopub.status.busy": "2021-11-21T15:51:44.930487Z",
          "iopub.status.idle": "2021-11-21T15:51:45.118177Z",
          "shell.execute_reply": "2021-11-21T15:51:45.117114Z",
          "shell.execute_reply.started": "2021-11-21T15:51:44.931346Z"
        },
        "trusted": true,
        "id": "CkCHt4NCa8rv"
      },
      "outputs": [],
      "source": [
        "#your code to clean the column \n",
        "tweet['TEXT'] = tweet['TEXT'].apply(lambda x:remove_html(str(x)))\n",
        "tweet['TEXT'] = tweet['TEXT'].apply(lambda x:_remove_urls(str(x)))\n",
        "#Apply _remove_emails, _remove_rt, _remove_special_chars, remove_digit\n",
        "\n",
        "\n",
        "#Convert Tweet['TEXT'] into lowercase with apply function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "O3WaNlKHa8rw"
      },
      "source": [
        "5/ Tokenize tweet['TEXT'] using tensorflow.keras. Store the result in X. Compute Y = tweet['class'].values to have the target values. What is the vocabulary size of the tokenization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:32:37.009754Z",
          "iopub.status.busy": "2021-11-21T15:32:37.009070Z",
          "iopub.status.idle": "2021-11-21T15:32:37.167081Z",
          "shell.execute_reply": "2021-11-21T15:32:37.166088Z",
          "shell.execute_reply.started": "2021-11-21T15:32:37.009701Z"
        },
        "trusted": true,
        "id": "VZTY9mQba8r0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "X_token = [d.split() for d in list(tweet['TEXT'])]\n",
        "tokenizer = Tokenizer()\n",
        "#code here \n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "execution": {
          "iopub.execute_input": "2021-09-04T14:09:46.998319Z",
          "iopub.status.busy": "2021-09-04T14:09:46.99799Z",
          "iopub.status.idle": "2021-09-04T14:09:47.006933Z",
          "shell.execute_reply": "2021-09-04T14:09:47.004788Z",
          "shell.execute_reply.started": "2021-09-04T14:09:46.998288Z"
        },
        "id": "SLP-mQgQa8r1"
      },
      "source": [
        "6/ X is a list of sequences as the result of tokenization. Plot a histogram of the sequence lengths. Make the padding process of X with maxlen=10 and truncating='post'. Store it in X_padd. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:32:48.276669Z",
          "iopub.status.busy": "2021-11-21T15:32:48.275959Z",
          "iopub.status.idle": "2021-11-21T15:32:48.495597Z",
          "shell.execute_reply": "2021-11-21T15:32:48.494720Z",
          "shell.execute_reply.started": "2021-11-21T15:32:48.276618Z"
        },
        "trusted": true,
        "id": "AZCui1jBa8r2"
      },
      "outputs": [],
      "source": [
        "#Plot the histogram of the sequence lengths\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist([len(x) for x in X],bins=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:32:59.685251Z",
          "iopub.status.busy": "2021-11-21T15:32:59.684767Z",
          "iopub.status.idle": "2021-11-21T15:32:59.740563Z",
          "shell.execute_reply": "2021-11-21T15:32:59.739522Z",
          "shell.execute_reply.started": "2021-11-21T15:32:59.685220Z"
        },
        "trusted": true,
        "id": "1c2etrKea8r3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = 10\n",
        "X_pad = #code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "XBT2KIYLa8r4"
      },
      "source": [
        "7/ After, Split X_pad and tweet['class'].to_numpy() into a train set and a test set using train_test_split from sklearn. You have to set test_size=0.20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:33:18.881222Z",
          "iopub.status.busy": "2021-11-21T15:33:18.880605Z",
          "iopub.status.idle": "2021-11-21T15:33:18.887844Z",
          "shell.execute_reply": "2021-11-21T15:33:18.886936Z",
          "shell.execute_reply.started": "2021-11-21T15:33:18.881188Z"
        },
        "trusted": true,
        "id": "imLnLPbma8r5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y_vect = tweet['class'].to_numpy()\n",
        "X_train, X_test, y_train, y_test = #your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Orb_5Xwva8r6"
      },
      "source": [
        "9) Create an LSTM network with the following layers :\n",
        "* an Embedding layer with output_dim=50. Output_dim is the embedding dimention. input_length argument should equal to the maxlen you used in question 6. The input is equal to the vocabulary size you finded in question 5\n",
        "* An LSTM layer with 64 units\n",
        "* A dropout with a rate 0.3\n",
        "* The output layer is a Dense layer\n",
        "\n",
        "Compile this LSTM with optimizer = 'adam' and metrics=['acc']. Train this LSTM with epochs=4 and validation_split=0.1. Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:33:31.266776Z",
          "iopub.status.busy": "2021-11-21T15:33:31.266421Z",
          "iopub.status.idle": "2021-11-21T15:33:40.606314Z",
          "shell.execute_reply": "2021-11-21T15:33:40.605652Z",
          "shell.execute_reply.started": "2021-11-21T15:33:31.266745Z"
        },
        "trusted": true,
        "id": "0Ig7UraAa8r7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense,LSTM, Embedding,Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "embedding_dim = 50\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:33:47.825909Z",
          "iopub.status.busy": "2021-11-21T15:33:47.825375Z",
          "iopub.status.idle": "2021-11-21T15:33:47.999159Z",
          "shell.execute_reply": "2021-11-21T15:33:47.997980Z",
          "shell.execute_reply.started": "2021-11-21T15:33:47.825873Z"
        },
        "trusted": true,
        "id": "S6n6hNR4a8r8"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train,y_train,epochs=4,validation_split=0.1)\n",
        "model.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8D7CZXsla8r9"
      },
      "source": [
        "10) Use the model you've just implemented to predict the emojis of the following tweets :\n",
        "  \n",
        "  * tweet_5 = 'Merry Christmas you filthy little animals. Wearing a @user ugly sweater featuring Santaâ€¦'\n",
        "  * tweet_11 = \"let's see those votes @ Merica\"\n",
        "  * tweet_0 = \"#Halloween Gig 2! E-Ticket will be going crazy tonight. I'll be there too I guess Sandy fromâ€¦\"\n",
        "  \n",
        "For this purpose you can use the function handle we define in the cell bellow. Before use this function you have to fite the model in question 9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:33:59.912990Z",
          "iopub.status.busy": "2021-11-21T15:33:59.912464Z",
          "iopub.status.idle": "2021-11-21T15:34:00.353005Z",
          "shell.execute_reply": "2021-11-21T15:34:00.352005Z",
          "shell.execute_reply.started": "2021-11-21T15:33:59.912956Z"
        },
        "trusted": true,
        "id": "bvBHoN_Va8r-"
      },
      "outputs": [],
      "source": [
        "tweet_5 = 'Merry Christmas you filthy little animals. Wearing a @user ugly sweater featuring Santaâ€¦'\n",
        "tweet_11 = \"let's see those votes @ Merica\"\n",
        "tweet_0 = \"#Halloween Gig 2! E-Ticket will be going crazy tonight. I'll be there too I guess Sandy fromâ€¦\"\n",
        "\n",
        "number_emoji = {0:'ðŸ‡ºðŸ‡¸',1:'ðŸŽ„',2:'ðŸ˜œ'}\n",
        "\n",
        "import numpy as np\n",
        "def handle(tweet):\n",
        "    clean_tweet = remove_html(str(tweet))\n",
        "    clean_tweet = _remove_urls(str(clean_tweet))\n",
        "    clean_tweet = _remove_emails(str(clean_tweet))\n",
        "    clean_tweet = _remove_rt(str(clean_tweet))\n",
        "    clean_tweet = _remove_special_chars(str(clean_tweet))\n",
        "    clean_tweet = remove_digit(str(clean_tweet))\n",
        "    clean_tweet = str(clean_tweet).lower()\n",
        "    clean_tweet_token=[clean_tweet.split()]\n",
        "    clean_tweet_sequence = tokenizer.texts_to_sequences(clean_tweet_token)\n",
        "    clean_tweet_sequence_pad = pad_sequences(clean_tweet_sequence,maxlen=10,truncating='post' )\n",
        "    clean_tweet_proba_vect = model.predict(clean_tweet_sequence_pad)\n",
        "    clean_tweet_class = np.argmax(clean_tweet_proba_vect)\n",
        "    #emojibis = le.inverse_transform([clean_tweet_class])[0]\n",
        "    emoji = number_emoji[clean_tweet_class]\n",
        "    return(emoji)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "execution": {
          "iopub.execute_input": "2021-09-04T14:14:01.334826Z",
          "iopub.status.busy": "2021-09-04T14:14:01.334509Z",
          "iopub.status.idle": "2021-09-04T14:14:13.779659Z",
          "shell.execute_reply": "2021-09-04T14:14:13.778836Z",
          "shell.execute_reply.started": "2021-09-04T14:14:01.334799Z"
        },
        "id": "N9O2WNuja8r_"
      },
      "source": [
        "11/ Build a Neural network model2 with the following layers:\n",
        "* an Embedding layer with output_dim=50. Output_dim is the embedding dimention. The input_dim is equal to the vocabulary size you finded in question 5\n",
        "* An LSTM layer with 64 units. You have to set return_sequences=True\n",
        "* A dropout with a rate 0.3\n",
        "* An LSTM layer with 32 units\n",
        "* A dropout with a rate 0.2\n",
        "* A dense layer with 10 units and a relu activation function.\n",
        "* The output layer is a Dense layer\n",
        "\n",
        "Compile model2. Don't train model2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:36:23.518142Z",
          "iopub.status.busy": "2021-11-21T15:36:23.517767Z",
          "iopub.status.idle": "2021-11-21T15:36:24.379718Z",
          "shell.execute_reply": "2021-11-21T15:36:24.378697Z",
          "shell.execute_reply.started": "2021-11-21T15:36:23.518105Z"
        },
        "trusted": true,
        "id": "TO9G_KrIa8r_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8SMta6pda8sA"
      },
      "source": [
        "12/ Build a bidirectional LSTM to handle the emoji prediction. You can retake the LSTM you built at the question 9. You only have to make a little change. Compile this bidirectional LSTM. Train this LSTM with 4 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T15:36:37.104352Z",
          "iopub.status.busy": "2021-11-21T15:36:37.103868Z",
          "iopub.status.idle": "2021-11-21T15:36:49.174811Z",
          "shell.execute_reply": "2021-11-21T15:36:49.173712Z",
          "shell.execute_reply.started": "2021-11-21T15:36:37.104322Z"
        },
        "trusted": true,
        "id": "yWO-NkJ7a8sB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense,LSTM, Embedding,Dropout, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "embedding_dim = 50\n",
        "\n",
        "#the number of units of the last dense layer\n",
        "output_size = len(np.unique(y_train)) #=20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2Z4Th3eua8sB"
      },
      "source": [
        "# Emoji prediction with CNN\n",
        "**This part is not a question** So far we have dealt with LSTM to solve NLP problems. It is possible to solve NLP tasks using a CNN (convolutional neural networks). Build a CNN with the following layers:\n",
        "* an Embedding layer with output_dim=50. Output_dim is the embedding dimention. input_length argument should equal to the maxlen you used in question 6. The input is equal to the vocabulary size you finded in question 5\n",
        "* a Conv1D layer with filters=32, kernel_size=3, activation='relu'\n",
        "* a GlobalMaxPooling1D()\n",
        "* a Dense layer with 10 units and activation='relu'\n",
        "* the output layer is a dense layer\n",
        "\n",
        "We call this model model_cnn. Compile this model. Train this model with 8 epochs and validation_split=0.1. Evaluate your model on the test set.<br>\n",
        "\n",
        "How many trainable parameters does model_cnn have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T14:56:37.200156Z",
          "iopub.status.busy": "2021-11-21T14:56:37.199774Z",
          "iopub.status.idle": "2021-11-21T14:56:44.633308Z",
          "shell.execute_reply": "2021-11-21T14:56:44.632350Z",
          "shell.execute_reply.started": "2021-11-21T14:56:37.200126Z"
        },
        "trusted": true,
        "id": "FciYjGvha8sC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Conv1D, Embedding, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "embedding_dim = 50\n",
        "maxlen = 10\n",
        "\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Embedding(vocab_size,output_dim = embedding_dim,input_length=maxlen))\n",
        "model_cnn.add(Conv1D(32, 3, activation='relu'))\n",
        "model_cnn.add(GlobalMaxPooling1D())\n",
        "model_cnn.add(Dense(10, activation='relu'))\n",
        "model_cnn.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model_cnn.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy',metrics=['acc'])\n",
        "\n",
        "model_cnn.fit(X_train,y_train,epochs=8,validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T14:56:49.894502Z",
          "iopub.status.busy": "2021-11-21T14:56:49.894142Z",
          "iopub.status.idle": "2021-11-21T14:56:50.005047Z",
          "shell.execute_reply": "2021-11-21T14:56:50.003911Z",
          "shell.execute_reply.started": "2021-11-21T14:56:49.894470Z"
        },
        "trusted": true,
        "id": "-iMgv6gqa8sD"
      },
      "outputs": [],
      "source": [
        "model_cnn.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-21T14:57:08.001348Z",
          "iopub.status.busy": "2021-11-21T14:57:08.000714Z",
          "iopub.status.idle": "2021-11-21T14:57:08.015142Z",
          "shell.execute_reply": "2021-11-21T14:57:08.013774Z",
          "shell.execute_reply.started": "2021-11-21T14:57:08.001310Z"
        },
        "trusted": true,
        "id": "RsKZUW72a8sE"
      },
      "outputs": [],
      "source": [
        "model_cnn.summary()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (system-wide)",
      "language": "python",
      "metadata": {
        "cocalc": {
          "description": "Python 3 programming language",
          "priority": 100,
          "url": "https://www.python.org/"
        }
      },
      "name": "python3",
      "resource_dir": "/ext/jupyter/kernels/python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "exercice-emoji-prediction-student.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}